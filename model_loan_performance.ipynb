{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('punkt') # Download the 'punkt' tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "import itertools  #used for flattening lists of lists\n",
    "import math\n",
    "import csv\n",
    "from help_functions import test_dictionary\n",
    "from help_functions import get_next_qtr\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stop Words, CSV Files, and Year List, SNL_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['before', 'between', 'about', 'o', \"shan't\", 'now', 'him', 'is', \"you've\", 'had', 'whom', 'out', \"she's\", 'wouldn', 'again', 'hasn', \"it's\", 'ours', 'how', \"hadn't\", 'shouldn', \"don't\", 'he', 'their', 'why', 'more', \"that'll\", 'mustn', 'there', 'i', 'our', 'are', 'was', \"mightn't\", 'd', 'isn', 'off', 'until', 'can', 'wasn', 'further', \"wasn't\", 'herself', 'to', 'yours', 'nor', \"aren't\", 'weren', 'yourselves', 'than', 'too', 'then', 'your', 'over', 'me', 'but', 've', 'doesn', 'aren', 'ain', 'after', 'yourself', \"mustn't\", 'were', 'don', 'a', 'with', \"couldn't\", 'couldn', 'his', 'own', \"didn't\", 'some', \"needn't\", 'these', 'from', 'through', 'down', \"doesn't\", 'hers', 'this', 'few', 'all', 'no', \"won't\", 'here', 'who', \"you'd\", 'its', 'just', 'it', 't', \"isn't\", 'will', 'has', 'on', 'under', 'same', 'having', 'in', \"weren't\", 'she', 'and', 'only', 'such', 'shan', 'didn', 'ourselves', 'does', 'while', 'any', 'because', 'be', 'doing', 'we', 'being', 'the', 'both', 'most', \"should've\", \"you're\", 'that', 'once', 'if', 'did', \"you'll\", 'myself', 'at', \"hasn't\", 'won', 'should', 'very', 'what', \"shouldn't\", \"wouldn't\", 'am', 'do', 'm', 'each', 'hadn', 're', 'mightn', 'themselves', 'up', 'where', 'ma', 'those', 'her', 'been', 'when', 'himself', 'as', 'against', 'y', 'my', 'have', 'of', 'them', 'they', 'll', 's', 'theirs', 'you', 'itself', 'or', 'into', 'which', 'during', 'by', 'other', 'needn', 'for', 'above', 'not', \"haven't\", 'so', 'an']\n",
      "\n",
      "['data\\\\bank_keydev_transcript_2009.csv', 'data\\\\bank_keydev_transcript_2010.csv', 'data\\\\bank_keydev_transcript_2011.csv', 'data\\\\bank_keydev_transcript_2012.csv', 'data\\\\bank_keydev_transcript_2013.csv', 'data\\\\bank_keydev_transcript_2014.csv', 'data\\\\bank_keydev_transcript_2015.csv', 'data\\\\bank_keydev_transcript_2016.csv', 'data\\\\bank_keydev_transcript_2017.csv', 'data\\\\bank_keydev_transcript_2018.csv', 'data\\\\bank_keydev_transcript_2019.csv', 'data\\\\bank_keydev_transcript_2020.csv', 'data\\\\bank_keydev_transcript_2021.csv', 'data\\\\bank_keydev_transcript_2022.csv', 'data\\\\bank_keydev_transcript_2023.csv', 'data\\\\bank_keydev_transcript_2024.csv']\n",
      "\n",
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+\n",
      "|   | transcript_id |  ciq_id  | snl_id  | quarter | year | total_asset_before | total_asset_after | loan_before | loan_after |     l2a_delta      | loan_diff |\n",
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+\n",
      "| 0 |    1790209    | 13314302 | 4055785 | Q4 2019 | 2019 |      12269288      |     12159919      |  10240434   |  10500284  | 0.0288763191369147 |  259850   |\n",
      "| 1 |    484381     | 2387628  | 4047200 | Q3 2012 | 2012 |      16509440      |     18242878      |  11459931   |  14593134  | 0.1057918149465313 |  3133203  |\n",
      "| 2 |    1177788    |  349262  | 102420  | Q3 2017 | 2017 |      1763750       |      1776911      |   1465917   |  1469842   |    -0.003947067    |   3925    |\n",
      "| 3 |    1759737    |  302423  | 100425  | Q3 2017 | 2017 |      5340299       |      5810129      |   3414438   |  3841682   | 0.0218321869692804 |  427244   |\n",
      "| 4 |    1441350    |  430453  | 4054569 | Q1 2018 | 2018 |      4369100       |      4221874      |   2066393   |  2164903   |     0.03982626     |   98510   |\n",
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+\n",
      "\n",
      "mapping files have been loaded in\n"
     ]
    }
   ],
   "source": [
    "nltk_stop_words = set(stopwords.words('english'))\n",
    "words_to_remove = ['below', 'haven']   #reasonable words to be meaningful\n",
    "stop_words = list(filter(lambda word: word not in words_to_remove, nltk_stop_words))\n",
    "print(stop_words)\n",
    "\n",
    "### create list of csv files and years\n",
    "csv_files = [os.path.join('data', file) for file in os.listdir('data')]\n",
    "years_list = list(range(2009, 2025))\n",
    "print('')\n",
    "print(csv_files)\n",
    "\n",
    "### create a look up file to get ciq id and map to related snl id\n",
    "snl_ciq_map = {}\n",
    "with open('snldata/SNl_CIQ_MAP.csv', mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) #skips first line\n",
    "    for row in reader:\n",
    "        snl_ciq_map[int(row[1][2:])] = int(row[0])\n",
    "\n",
    "### import csv as dataframes for transcript/company ids and loan data/snl ids\n",
    "delta_df = pd.read_csv('snldata/transcript_loans.csv', encoding='utf-8')\n",
    "print('')\n",
    "print(tabulate(delta_df.head(), headers='keys', tablefmt='pretty'))\n",
    "\n",
    "print('')\n",
    "print(f'mapping files have been loaded in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition for Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_bundles:\n",
    "  bundle_dict = {}\n",
    "\n",
    "  def __init__(self, year, model, uncertainty_wordlist, corpus_bigrams, bigram_dict, flat_corpus_bigrams):\n",
    "\n",
    "    self.year = year\n",
    "    self.model = model\n",
    "    self.uncertainty_wordlist = uncertainty_wordlist\n",
    "    self.corpus_bigrams = corpus_bigrams\n",
    "    self.bigram_dict = bigram_dict\n",
    "    self.flat_corpus_bigrams = flat_corpus_bigrams\n",
    "    self.idf_dict = create_idf_dict(self)\n",
    "\n",
    "    model_bundles.bundle_dict[year] = self\n",
    "\n",
    "class allyr_model:\n",
    "\n",
    "  def __init__(self, model, uncertainty_wordlist, corpus_bigrams, bigram_dict, flat_corpus_bigrams):\n",
    "\n",
    "    self.model = model\n",
    "    self.uncertainty_wordlist = uncertainty_wordlist\n",
    "    self.corpus_bigrams = corpus_bigrams\n",
    "    self.bigram_dict = bigram_dict\n",
    "    self.flat_corpus_bigrams = flat_corpus_bigrams\n",
    "    self.idf_dict = create_idf_dict(self)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_sentences_words(text):\n",
    "    # Split into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Split each sentence into a list of words\n",
    "    sentences_words = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    return sentences_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Corpus, Process Data, and Create Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes single csv file and returns dictionary transcipt_id: [[word, word, word],[word, word, word]]\n",
    "def get_corpus(csv_file):\n",
    "   df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "   df['COMPONENTTEXT_SPLIT'] = df['COMPONENTTEXT'].apply(split_text_to_sentences_words)\n",
    "\n",
    "   unprocessed_dict = {}\n",
    "   for row in df.itertuples():\n",
    "      if row.TRANSCRIPTID not in unprocessed_dict:\n",
    "         unprocessed_dict[row.TRANSCRIPTID] = row.COMPONENTTEXT_SPLIT\n",
    "      else:\n",
    "         unprocessed_dict[row.TRANSCRIPTID].extend(row.COMPONENTTEXT_SPLIT)\n",
    "   return unprocessed_dict\n",
    "\n",
    "#takes unprocessed dict and returns processed dict\n",
    "def process_the_data(unprocessed_dict, stop_words):\n",
    "   num_tokens_before = 0\n",
    "   num_tokens_after = 0\n",
    "   processed_dict = {}\n",
    "\n",
    "   for transcriptid, text in unprocessed_dict.items():\n",
    "      p_text = []\n",
    "      for sentence in text:\n",
    "         p_sentence = []\n",
    "         for word in sentence:\n",
    "            num_tokens_before += 1\n",
    "            p_word = word.lower()                                  #lowercase the text\n",
    "            p_word = re.sub(r'(?<!\\w)-(?!\\w)|[^\\w\\s-]', '', p_word)  #remove punctuation but keep hyphens\n",
    "            if p_word in stop_words or len(p_word) == 0:             #ignore if word has no length (ie was punctuation only) or in stop words\n",
    "               continue\n",
    "            p_sentence.append(p_word)\n",
    "         p_text.append(p_sentence)\n",
    "         num_tokens_after += len(p_sentence)\n",
    "      processed_dict[transcriptid] = p_text\n",
    "   return processed_dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "below function creates:\n",
    "corpus_bigrams (list of sentences for full corpus to run through word2vec\n",
    "dict_bigrams: links transcript id to corpus for uncertainty calc\n",
    "flat_corpus_bigrams: flat version of corpus bigrams for counting word appearances easily\n",
    "\"\"\"\n",
    "\n",
    "def create_bigrams(processed_dict, min_count=10, threshold = 100):\n",
    "   processed_corpus = [['']]\n",
    "   for value in processed_dict.values():\n",
    "      processed_corpus.extend(value)\n",
    "\n",
    "   phrases = Phrases(processed_corpus, min_count, threshold, scoring='default')\n",
    "   bigram_phraser = Phraser(phrases)\n",
    "\n",
    "   corpus_bigrams = [['']]\n",
    "\n",
    "   dict_bigrams = {}\n",
    "   for transcript_id, text in processed_dict.items():\n",
    "      bigram_text = [bigram_phraser[sentence] for sentence in text]\n",
    "      dict_bigrams[transcript_id] = bigram_text\n",
    "      corpus_bigrams.extend(bigram_text)\n",
    "\n",
    "\n",
    "   flat_corpus_bigrams = [item for sublist in corpus_bigrams for item in sublist]\n",
    "\n",
    "   # print('bigrams created')\n",
    "   return phrases, bigram_phraser, corpus_bigrams, dict_bigrams, flat_corpus_bigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IDF dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_idf_dict(bundle):\n",
    "    idf_dict = {}\n",
    "    n = len(bundle.bigram_dict)\n",
    "    for word in bundle.uncertainty_wordlist:\n",
    "        t = 0\n",
    "        for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "            transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "            if word in transcript_text:\n",
    "                t+=1\n",
    "\n",
    "        idf= math.log2(n/t)\n",
    "        idf_dict[word] = idf\n",
    "\n",
    "    return idf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Uncertainty scores - regular and soto variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uncertainty_reg(bundle, delta_df, column_name):\n",
    "    for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "        transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "        uncty_cnt = 0\n",
    "        for word in transcript_text:\n",
    "            if word in bundle.uncertainty_wordlist:\n",
    "                uncty_cnt += 1\n",
    "        uncty_score = uncty_cnt/len(transcript_text)\n",
    "        try:\n",
    "            delta_df.loc[delta_df['transcript_id'] == transcript_id, column_name] = uncty_score\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def calc_uncertainty_soto(bundle, delta_df, column_name):\n",
    "    for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "        transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "        word_count_dict = Counter(transcript_text)\n",
    "        d = len(transcript_text)\n",
    "        tf_idf_sum = 0\n",
    "        for word in full_model.uncertainty_wordlist:\n",
    "            if word in transcript_text:\n",
    "                t = word_count_dict[word]\n",
    "                tf = t/d\n",
    "                idf = full_model.idf_dict[word]\n",
    "                tf_idf = tf*idf\n",
    "                tf_idf_sum += tf_idf\n",
    "\n",
    "        uncty_score = tf_idf_sum/len(set(transcript_text))\n",
    "        try:\n",
    "            delta_df.loc[delta_df['transcript_id'] == transcript_id, column_name] = uncty_score\n",
    "            # print(uncty_score)\n",
    "        except KeyError:\n",
    "            # print(f'{transcript_id}: key error')\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend yearly corpus to full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_to_full(model_bundle_dict):\n",
    "    corpus_bigrams_allyrs = []\n",
    "    flat_corpus_allyrs = []\n",
    "    bigram_dict_allyrs = {}\n",
    "\n",
    "    for year, bundle in model_bundle_dict.items():\n",
    "        corpus_bigrams_allyrs.extend(bundle.corpus_bigrams)\n",
    "        flat_corpus_allyrs.extend(bundle.flat_corpus_bigrams)\n",
    "        bigram_dict_allyrs.update(bundle.bigram_dict)\n",
    "\n",
    "    return corpus_bigrams_allyrs,flat_corpus_allyrs,bigram_dict_allyrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_word2vec(corpus_bigrams):\n",
    "   model = gensim.models.Word2Vec (\n",
    "    vector_size=150,    # Number of features in word vector\n",
    "\n",
    "    window=10,   # Context window size (in each direction). Default is 5\n",
    "\n",
    "\n",
    "    min_count=5, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "\n",
    "    workers=10,  # Training thread count\n",
    "\n",
    "    sg=1,        # 0: CBOW, 1: Skip-gram.\n",
    "\n",
    "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "    negative=5   # Nmber of negative samples\n",
    "                 #   Default is 5\n",
    "   )\n",
    "\n",
    "   model.build_vocab(\n",
    "    corpus_bigrams,\n",
    "    progress_per=20000  # Tweaks how often progress is reported\n",
    "   )\n",
    "\n",
    "   model.train(\n",
    "    corpus_bigrams,\n",
    "    total_examples=len(corpus_bigrams),\n",
    "    epochs=10,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    "   )\n",
    "\n",
    "   return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!!\n"
     ]
    }
   ],
   "source": [
    "for index, file in enumerate(csv_files):\n",
    "    corpus_dict = get_corpus(file)\n",
    "    processed_corpus_dict = process_the_data(corpus_dict, stop_words)\n",
    "    phrases, bigram_phraser, corpus_bigrams, bigram_dict, flat_corpus_bigrams = create_bigrams(processed_corpus_dict)\n",
    "    trained_model = apply_word2vec(corpus_bigrams)\n",
    "\n",
    "    similar_words = trained_model.wv.most_similar('uncertainty', topn=100)\n",
    "    word_list = [word for word, number in similar_words]\n",
    "\n",
    "    model_bundles(year=years_list[index], model=trained_model, uncertainty_wordlist=word_list,\n",
    "               corpus_bigrams=corpus_bigrams, bigram_dict=bigram_dict, flat_corpus_bigrams = flat_corpus_bigrams)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!!\n"
     ]
    }
   ],
   "source": [
    "corpus_bigrams_allyrs,flat_corpus_allyrs,bigram_dict_allyrs = extend_to_full(model_bundles.bundle_dict)\n",
    "trained_model = apply_word2vec(corpus_bigrams_allyrs)\n",
    "similar_words = trained_model.wv.most_similar('uncertainty', topn=150)\n",
    "word_list = [word for word, number in similar_words]\n",
    "\n",
    "full_model = allyr_model(model=trained_model, uncertainty_wordlist=word_list,\n",
    "               corpus_bigrams=corpus_bigrams_allyrs, bigram_dict = bigram_dict_allyrs, flat_corpus_bigrams = flat_corpus_allyrs)\n",
    "\n",
    "print('done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc Uncertainty Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, bundle in model_bundles.bundle_dict.items():\n",
    "    for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "        transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "        uncty_cnt = 0\n",
    "        for word in transcript_text:\n",
    "            if word in bundle.uncertainty_wordlist:\n",
    "                uncty_cnt += 1\n",
    "        uncty_score = uncty_cnt/len(transcript_text)\n",
    "        try:\n",
    "            delta_df.loc[delta_df['transcript_id'] == transcript_id, 'year_uncertainty_score'] = uncty_score\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "\n",
    "for transcript_id, bigrams in full_model.bigram_dict.items():\n",
    "    transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "\n",
    "    uncty_cnt = 0\n",
    "    for word in transcript_text:\n",
    "        if word in full_model.uncertainty_wordlist:\n",
    "            uncty_cnt += 1\n",
    "    uncty_score = uncty_cnt/len(transcript_text)\n",
    "    try:\n",
    "        delta_df.loc[delta_df['transcript_id'] == transcript_id, 'full_uncertainty_score'] = uncty_score\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, bundle in model_bundles.bundle_dict.items():\n",
    "    calc_uncertainty_reg(bundle, delta_df, 'year_uncertainty_score_reg')\n",
    "\n",
    "\n",
    "calc_uncertainty_reg(full_model, delta_df, 'full_uncertainty_score_reg')\n",
    "\n",
    "for year, bundle in model_bundles.bundle_dict.items():\n",
    "    calc_uncertainty_soto(bundle, delta_df, 'year_uncertainty_score_soto')\n",
    "\n",
    "\n",
    "calc_uncertainty_soto(full_model, delta_df, 'full_uncertainty_score_soto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year, bundle in model_bundles.bundle_dict.items():\n",
    "#     idf_dict = {}\n",
    "#     n = len(bundle.bigram_dict)\n",
    "#     for word in bundle.uncertainty_wordlist:\n",
    "#         t = 0\n",
    "#         for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "#             transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "#             if word in transcript_text:\n",
    "#                 t+=1\n",
    "\n",
    "#         idf= math.log2(n/t)\n",
    "#         idf_dict[word] = idf\n",
    "\n",
    "#     bundle.idf_dict = idf_dict\n",
    "\n",
    "\n",
    "# idf_dict = {}\n",
    "# n = len(full_model.bigram_dict)\n",
    "# for word in full_model.uncertainty_wordlist:\n",
    "#     t = 0\n",
    "#     for transcript_id, bigrams in full_model.bigram_dict.items():\n",
    "#         transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "#         if word in transcript_text:\n",
    "#             t+=1\n",
    "\n",
    "#     idf= math.log2(n/t)\n",
    "#     idf_dict[word] = idf\n",
    "\n",
    "# full_model.idf_dict = idf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, bundle in model_bundles.bundle_dict.items():\n",
    "    for transcript_id, bigrams in bundle.bigram_dict.items():\n",
    "        transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "        word_count_dict = Counter(transcript_text)\n",
    "        d = len(transcript_text)\n",
    "        tf_idf_sum = 0\n",
    "        for word in bundle.uncertainty_wordlist:\n",
    "            if word in transcript_text:\n",
    "                t = word_count_dict[word]\n",
    "                tf = t/d\n",
    "                idf = bundle.idf_dict[word]\n",
    "                tf_idf = tf*idf\n",
    "                tf_idf_sum += tf_idf\n",
    "\n",
    "        uncty_score = tf_idf_sum/len(set(transcript_text))\n",
    "        try:\n",
    "            # print(f'uncertainty score:{uncty_score}| tf_idf_sum = {tf_idf_sum}| transcript_id = {transcript_id}| d = {d}')\n",
    "            delta_df.loc[delta_df['transcript_id'] == transcript_id, 'full_uncertainty_score_soto'] = uncty_score\n",
    "            # print(uncty_score)\n",
    "        except KeyError:\n",
    "            # print(f'{transcript_id}: key error')\n",
    "            continue\n",
    "\n",
    "\n",
    "for transcript_id, bigrams in full_model.bigram_dict.items():\n",
    "    transcript_text = list(itertools.chain.from_iterable(bigrams))\n",
    "    word_count_dict = Counter(transcript_text)\n",
    "    d = len(transcript_text)\n",
    "    tf_idf_sum = 0\n",
    "    for word in full_model.uncertainty_wordlist:\n",
    "        if word in transcript_text:\n",
    "            t = word_count_dict[word]\n",
    "            tf = t/d\n",
    "            idf = full_model.idf_dict[word]\n",
    "            tf_idf = tf*idf\n",
    "            tf_idf_sum += tf_idf\n",
    "\n",
    "    uncty_score = tf_idf_sum/len(set(transcript_text))\n",
    "    try:\n",
    "        delta_df.loc[delta_df['transcript_id'] == transcript_id, 'year_uncertainty_score_soto'] = uncty_score\n",
    "        # print(uncty_score)\n",
    "    except KeyError:\n",
    "        # print(f'{transcript_id}: key error')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+----------------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|   | transcript_id |  ciq_id  | snl_id  | quarter | year | total_asset_before | total_asset_after | loan_before | loan_after |     l2a_delta      | loan_diff | year_uncertainty_score_reg | full_uncertainty_score_reg | year_uncertainty_score_soto | full_uncertainty_score_soto |\n",
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+----------------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "| 0 |    1790209    | 13314302 | 4055785 | Q4 2019 | 2019 |      12269288      |     12159919      |  10240434   |  10500284  | 0.0288763191369147 |  259850   |   0.0005747126436781609    |   0.0011494252873563218    |    2.587497451365979e-06    |    2.587497451365979e-06    |\n",
      "| 1 |    484381     | 2387628  | 4047200 | Q3 2012 | 2012 |      16509440      |     18242878      |  11459931   |  14593134  | 0.1057918149465313 |  3133203  |   0.0009442870632672333    |   0.0012590494176896443    |   1.1959587804109582e-06    |   1.1959587804109582e-06    |\n",
      "| 2 |    1177788    |  349262  | 102420  | Q3 2017 | 2017 |      1763750       |      1776911      |   1465917   |  1469842   |    -0.003947067    |   3925    |            0.0             |   0.0012507817385866166    |    5.085670899901623e-06    |    5.085670899901623e-06    |\n",
      "| 3 |    1759737    |  302423  | 100425  | Q3 2017 | 2017 |      5340299       |      5810129      |   3414438   |  3841682   | 0.0218321869692804 |  427244   |            0.0             |   0.0006487187804086928    |    4.252021426338837e-07    |    4.252021426338837e-07    |\n",
      "| 4 |    1441350    |  430453  | 4054569 | Q1 2018 | 2018 |      4369100       |      4221874      |   2066393   |  2164903   |     0.03982626     |   98510   |   0.0006493506493506494    |    0.001948051948051948    |    4.70538248122395e-06     |    4.70538248122395e-06     |\n",
      "+---+---------------+----------+---------+---------+------+--------------------+-------------------+-------------+------------+--------------------+-----------+----------------------------+----------------------------+-----------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(delta_df.head(), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Word Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model_year.years.items():\n",
    "\n",
    "    print(f'{key}: {value.uncertainty_wordlist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf_scores = {}\n",
    "# n = len(years_list)\n",
    "\n",
    "# for object in model_year.years.values():\n",
    "#     for word in object.uncertainty_wordlist:\n",
    "#         if word not in idf_scores.keys():\n",
    "#             count = 0\n",
    "\n",
    "#             for object in model_year.years.values():\n",
    "#                 if word in object.flat_corpus_bigrams:\n",
    "#                     count += 1\n",
    "\n",
    "\n",
    "\n",
    "#         # print(f'{word}:({n}/{1+count})')\n",
    "#         idf = math.log(n/(1+count))\n",
    "#         idf_scores[word] = idf\n",
    "\n",
    "# print(idf_scores)\n",
    "\n",
    "idf_scores = {}\n",
    "n = len(years_list)\n",
    "\n",
    "for object in model_year.years.values():\n",
    "    for word in object.uncertainty_wordlist:\n",
    "        if word not in idf_scores.keys():\n",
    "            count = 0\n",
    "\n",
    "            for object in model_year.years.values():\n",
    "                if word in object.uncertainty_wordlist:\n",
    "                    count += 1\n",
    "\n",
    "        print(f'{word}:({n}/{1+count})')\n",
    "        idf = math.log(n/(1+count))\n",
    "        idf_scores[word] = idf\n",
    "\n",
    "# print(idf_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = empty_df = pd.DataFrame(index=years_list, columns=idf_scores.keys())\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_uncertainty_wordlist = []\n",
    "\n",
    "for year in years_list:\n",
    "    for uncertainty_word in model_year.years[year].uncertainty_wordlist:\n",
    "        if uncertainty_word not in combined_uncertainty_wordlist:\n",
    "            combined_uncertainty_wordlist.append(uncertainty_word)\n",
    "\n",
    "print(len(combined_uncertainty_wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count total instances of word\n",
    "for year in years_list:\n",
    "    word_counts = Counter((model_year.years[year].flat_corpus_bigrams))\n",
    "    for uncertainty_word in combined_uncertainty_wordlist:\n",
    "        count = word_counts[uncertainty_word]\n",
    "        tfidf_df.at[year, uncertainty_word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years_list:\n",
    "    print(year)\n",
    "    for word in model_year.years[year].uncertainty_wordlist:\n",
    "        average_count = tfidf_df[word].mean()\n",
    "        year_count = tfidf_df.at[year, word]\n",
    "\n",
    "        if year_count/average_count > 3:\n",
    "            print(f\"{word} | {year_count} / {average_count}\")\n",
    "    print()\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = model_year.years[2024].flat_corpus_bigrams.index('qt')\n",
    "print(index)\n",
    "start = max(0, index - 10)\n",
    "end = min(len(word_list), index + 11)\n",
    "\n",
    "print(model_year.years[2024].flat_corpus_bigrams[index - 10:index + 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tfidf_df.columns:\n",
    "    for year in years_list:\n",
    "        idf = idf_scores[word]\n",
    "\n",
    "        doc_length = len(model_year.years[year].uncertainty_wordlist)\n",
    "        count = 0\n",
    "\n",
    "        for checked_word in model_year.years[year].uncertainty_wordlist:\n",
    "            if word == checked_word:\n",
    "                count+=1\n",
    "\n",
    "        tf = count/doc_length\n",
    "        tf_idf = tf * idf\n",
    "\n",
    "        tfidf_df.at[year, word] = tf_idf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def top_10_columns_by_row(row):\n",
    "#     # Sort values in descending order and get top 10 columns\n",
    "#     return row.nlargest(10).index.tolist()\n",
    "\n",
    "# df['top_10_columns'] = tfidf_df.apply(top_10_columns_by_row, axis=1)\n",
    "# print(df[['top_10_columns']])\n",
    "\n",
    "for index, row in tfidf_df.iterrows():\n",
    "    # Sort row values in descending order and print top 10 with column names\n",
    "    print(f\"Row {index}:\")\n",
    "    sorted_row = row.sort_values(ascending=False)\n",
    "\n",
    "    # Print column names and values for the top 10 items\n",
    "    for col, value in sorted_row.head(20).items():\n",
    "        print(f\"{col}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_year.years[2010].corpus_bigrams[1:5])\n",
    "print(len(model_year.years[2010].corpus_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for year, model in model_year.years.items():\n",
    "    score_list = [0] * len(model.uncertainty_wordlist)  #create dummy holder for frequency scores\n",
    "\n",
    "    for index, word in enumerate(model.uncertainty_wordlist):\n",
    "        count = 0\n",
    "        for model in model_year.years.values():\n",
    "            if word in model.uncertainty_wordlist:\n",
    "                count += 1\n",
    "        score_list[index] = count\n",
    "    scores[year] = score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, score_list in scores.items():\n",
    "    print(year)\n",
    "    for index, score in enumerate(score_list):\n",
    "        if score < 2:\n",
    "            print(f'{model_year.years[year].uncertainty_wordlist[index]} : {score}')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = trained_model.wv.most_similar('uncertainty', topn=100)\n",
    "word_list = [word for word, number in similar_words]\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scatter plot of uncertainty score vs loan movement\n",
    "plt.scatter(delta_df['uncertainty_score'], delta_df['l2a_delta'])\n",
    "plt.xlabel('Uncertainty Score')\n",
    "plt.ylabel('Loan Movement')\n",
    "plt.title('Uncertainty Score vs Loan Movement')\n",
    "plt.show()\n",
    "\n",
    "correlation = delta_df['uncertainty_score'].corr(delta_df['l2a_delta'])\n",
    "print(f\"Correlation between Uncertainty Score and Loan Movement: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
