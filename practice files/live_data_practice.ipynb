{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('punkt') # Download the 'punkt' tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"you've\", 'who', \"shouldn't\", 'been', \"haven't\", 'your', 'a', 'couldn', 'have', 'other', 'theirs', \"won't\", 'mightn', \"she's\", 'were', 'him', 'each', 'i', 'all', 'after', \"doesn't\", 'myself', 'so', 'them', 'very', 'off', \"mightn't\", 'be', 't', 'does', 'than', \"isn't\", 'any', 'now', 'an', 'same', 'between', 'you', 'once', 'their', 'm', 'mustn', 'my', \"weren't\", 'whom', 'at', \"wouldn't\", 'such', \"hadn't\", 'these', 'ain', 'needn', \"aren't\", 'most', 'over', 're', 'herself', 'which', 'too', 'his', 'both', 'won', 'more', 'ma', 'isn', 'but', 'in', 'above', 'why', 'yours', 'themselves', \"that'll\", 'against', 'will', 'into', 'just', \"you're\", 'what', 'had', 'did', 'by', 's', 'they', 'she', 'll', 'until', 'those', 'during', 'if', 'can', 'where', 'no', 'shouldn', 'when', \"wasn't\", \"shan't\", 'do', 'down', 'wouldn', 'was', 'as', 'this', 'shan', 'while', 'hasn', 'itself', 'is', \"didn't\", 'didn', \"couldn't\", 'has', 'not', 've', 'y', 'aren', \"don't\", 'am', 'being', 'with', \"hasn't\", 'only', 'doesn', 'are', 'wasn', 'hers', 'it', 'yourselves', 'further', 'the', 'from', 'yourself', 'and', 'or', 'd', \"you'd\", \"you'll\", 'few', \"should've\", 'having', 'me', 'ourselves', \"it's\", 'because', 'before', 'up', 'some', 'for', 'weren', 'its', 'himself', 'that', 'we', 'of', 'out', 'again', 'here', 'then', 'there', 'he', 'hadn', 'about', 'doing', \"needn't\", 'o', 'nor', 'on', 'how', 'don', 'should', 'our', 'under', \"mustn't\", 'to', 'ours', 'her', 'own', 'through']\n"
     ]
    }
   ],
   "source": [
    "nltk_stop_words = set(stopwords.words('english'))\n",
    "words_to_remove = ['below', 'haven']\n",
    "stop_words = list(filter(lambda word: word not in words_to_remove, nltk_stop_words))\n",
    "print(stop_words)\n",
    "\n",
    "corpus = brown.sents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\bank_keydev_transcript_2009.csv', 'data\\\\bank_keydev_transcript_2010.csv', 'data\\\\bank_keydev_transcript_2011.csv', 'data\\\\bank_keydev_transcript_2012.csv', 'data\\\\bank_keydev_transcript_2013.csv', 'data\\\\bank_keydev_transcript_2014.csv', 'data\\\\bank_keydev_transcript_2015.csv', 'data\\\\bank_keydev_transcript_2016.csv', 'data\\\\bank_keydev_transcript_2017.csv', 'data\\\\bank_keydev_transcript_2018.csv', 'data\\\\bank_keydev_transcript_2019.csv', 'data\\\\bank_keydev_transcript_2020.csv', 'data\\\\bank_keydev_transcript_2021.csv', 'data\\\\bank_keydev_transcript_2022.csv', 'data\\\\bank_keydev_transcript_2023.csv', 'data\\\\bank_keydev_transcript_2024.csv']\n"
     ]
    }
   ],
   "source": [
    "directory = \"data\"\n",
    "csv_files = [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "# print(csv_files)\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, encoding='utf-8')\n",
    "    dfs.append(df)\n",
    "large_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "num_rows = large_df.shape[0]\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(large_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_sentences_words(text):\n",
    "    # Split into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "    # Split each sentence into a list of words\n",
    "    sentences_words = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    return sentences_words\n",
    "\n",
    "def get_corpus(directory):\n",
    "    csv_files = [os.path.join(directory, file) for file in os.listdir(directory)]\n",
    "# print(csv_files)\n",
    "\n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file, encoding='utf-8')\n",
    "        dfs.append(df)\n",
    "    large_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    num_rows = large_df.shape[0]\n",
    "    print(f\"Number of rows: {num_rows}\")\n",
    "    print(tabulate(large_df.head(2), headers='keys', tablefmt='pretty'))\n",
    "    large_df['COMPONENTTEXT_SPLIT'] = large_df['COMPONENTTEXT'].apply(split_text_to_sentences_words)\n",
    "\n",
    "    all_sentences = []\n",
    "\n",
    "    for sentences in large_df['COMPONENTTEXT_SPLIT']:\n",
    "    # Add each sentence (which is a list of words) to the master list\n",
    "        all_sentences.extend(sentences)\n",
    "\n",
    "    print(f'length of all_sentences: {len(all_sentences)}')\n",
    "    return(all_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_the_data(corpus, stop_words):\n",
    "\n",
    "   #count tokens before processing\n",
    "   flattened_list = [word for sentence in corpus for word in sentence]\n",
    "   print(f'Number of Tokens before processing: {len(flattened_list):,}')\n",
    "   print()\n",
    "\n",
    "   num_tokens = 0\n",
    "   processed_sents = []\n",
    "   for sent in corpus:\n",
    "      p_sentence = []\n",
    "      for word in sent:\n",
    "         text = word.lower()                                  #lowercase the text\n",
    "         text = re.sub(r'(?<!\\w)-(?!\\w)|[^\\w\\s-]', '', text)  #remove punctuation but keep hyphens\n",
    "         if text in stop_words or len(text) == 0:             #ignore if word has no length (ie was punctuation only) or in stop words\n",
    "            continue\n",
    "         p_sentence.append(text)\n",
    "      processed_sents.append(p_sentence)\n",
    "      num_tokens += len(p_sentence)\n",
    "\n",
    "   #count tokens after processing\n",
    "   print(f'Number of Tokens after processing: {num_tokens:,}')\n",
    "   print(f'Process Sentence Examples:')\n",
    "   for i in processed_sents[:3]:\n",
    "      print(i)\n",
    "\n",
    "   return processed_sents\n",
    "\n",
    "def create_bigrams(processed_corpus):\n",
    "   phrases = Phrases(processed_corpus, min_count=10, threshold=100, scoring='default')\n",
    "   bigram_phraser = Phraser(phrases)\n",
    "\n",
    "   corpus_bigrams = [bigram_phraser[sentence] for sentence in processed_corpus]\n",
    "\n",
    "   print('bigrams created')\n",
    "\n",
    "   return phrases, bigram_phraser, corpus_bigrams\n",
    "\n",
    "def apply_word2vec(corpus_bigrams):\n",
    "   model = gensim.models.Word2Vec (\n",
    "    vector_size=100,    # Number of features in word vector\n",
    "\n",
    "    window=10,   # Context window size (in each direction). Default is 5\n",
    "\n",
    "\n",
    "    min_count=5, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "\n",
    "    workers=10,  # Training thread count\n",
    "\n",
    "    sg=1,        # 0: CBOW, 1: Skip-gram.\n",
    "\n",
    "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "    negative=5   # Nmber of negative samples\n",
    "                 #   Default is 5\n",
    "   )\n",
    "\n",
    "   model.build_vocab(\n",
    "    corpus_bigrams,\n",
    "    progress_per=20000  # Tweaks how often progress is reported\n",
    "   )\n",
    "\n",
    "   print('Training the model...')\n",
    "\n",
    "   model.train(\n",
    "    corpus_bigrams,\n",
    "    total_examples=len(corpus_bigrams),\n",
    "    epochs=10,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    "   )\n",
    "\n",
    "   print(' Modeling Training Done.')\n",
    "   print('')\n",
    "\n",
    "   return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 553450\n",
      "+---+-----------+------------------------+---------------+---------------------------+----------+---------------------+------------------------------------------------------------+------------------------------+--------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|   | COMPANYID |      COMPANYNAME       |    COUNTRY    | SIMPLEINDUSTRYDESCRIPTION | KEYDEVID | KEYDEVEVENTTYPENAME |                          HEADLINE                          | YEAR(E.MOSTIMPORTANTDATEUTC) | TRANSCRIPTID | COMPONENTORDER |                                                                                                                                                                                                                                                                                            COMPONENTTEXT                                                                                                                                                                                                                                                                                             |\n",
      "+---+-----------+------------------------+---------------+---------------------------+----------+---------------------+------------------------------------------------------------+------------------------------+--------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| 0 |  247106   | AMCORE Financial, Inc. | United States |           Banks           | 6372848  |   Earnings Calls    | AMCORE Financial, Inc., Q1 2009 Earnings Call, Apr-28-2009 |             2009             |    20338     |       1        |                                                                              Good morning, ladies and gentlemen. And welcome to the AMCORE Financial first quarter earnings result conference call. At this time, participants are in a listen only mode. Later we will conduct a question-and-answer session for analysts only. Please note that this conference is being recorded. This conference call is also being webcast and can be accessed at www.amcore.com, and will be archived for additional four weeks.                                                                               |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                | Statements made in the course of this conference call stating the company’s or management’s intentions hopes, beliefs, expectations, or predictions of the future are considered forward-looking statements. It is important to note that the company’s actual results could differ materially from those projected in such forward-looking statements. Additional information concerning factors that could cause actual result to differ materially from those in the forward-looking statements, is contained from time-to-time in the company's SEC filings and within the press release itself. |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                                                                                                       Conducting the call today will be Mr. William McManaman, Chief Executive Officer, and Ms. Judith Carre Sutfin, Chief Financial Officer. I’ll now turn the call over to Mr. Bill McManaman. Mr. McManaman, you may begin.                                                                                                                                                                                       |\n",
      "| 1 |  247106   | AMCORE Financial, Inc. | United States |           Banks           | 6372848  |   Earnings Calls    | AMCORE Financial, Inc., Q1 2009 Earnings Call, Apr-28-2009 |             2009             |    20338     |       2        |                                                                                                                                        Thank you, and good morning. We appreciate the time you’ve taken to listen to this conference call, and welcome questions from our analysts at the end of my comments. We assume that you have seen a copy of the press release we issued last night. If not, you can find the copy on our Web site at www.amcore.com.                                                                                                                                        |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                                                       We all recognize that this continues to be a very difficult and weak economy, especially for banks. The nation is experiencing one of the worst economic recessions in decades. Unemployment rates hit 25-year highs, consumer confidence has plummeted, and foreclosures are climbing to their highest levels in years.                                                                                                                                       |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                  Our first quarter results reflect the continued deterioration of the economic environment, and our concentration in construction and development loans. Many of these builders and developers carry extended housing inventories in a weak market, placing an escalating strain on their liquidity as conditions have worsened. These conditions have not yet abated and continued to have an impact on our financial performance.                                                                                  |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                             It should come as no surprise that these unprecedented economic conditions demand new ways of operating. The bank’s infrastructure, specifically our operating expenses in relation to the assets we manage, the revenue we generate, and our expected growth rates, was built for more expansionary economy. Put simply, our annualized operating expenses of roughly $175 million were too high for the realities of today’s marketplace.                                                                              |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                                                      We made progress in 2008, reducing our cost by $6 million on a gross basis. This involved an 11% reduction in work force, in addition to other administrative and consolidation changes to decrease expenses. Some of these savings were offset by significantly higher FDIC premiums and increased loan collection costs.                                                                                                                                      |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                       We announced significant organizational changes last night that better align the size and management structure of our organization with the current economic environment. We were not able to act sooner with respect to these changes until we had demonstrated that we had made substantial progress in improving our lending processes and disciplines. The changes announced today streamline the organization, but will not compromise the disciplines, controls, and improvements implemented over the past year.                                        |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                             We are working on those things that we can control. From yesterday’s announcement, you know we eliminated an additional 116 positions, including two executive positions, that of Don Wilson, President and Chief Operating Officer, and Rick Stiles, Executive Vice President, commercial banking. The company is grateful for their services and contributions to AMCORE.                                                                                                              |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                       We also eliminated merit increases for all employees, reduced executive salaries 5%, decreased the company contribution to the 401-K plan, and modified our branch hours to more closely align with customer usage. In the second quarter we expect to take an estimated restructuring charge of $2 million, for severance and related costs. We expect annual savings of approximately $20 million from these actions.                                                                                        |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                                                                                                                           The total annual cost reductions from changes made during the last five quarters now approximate $26 million. This will have significant benefit for the company going forward.                                                                                                                                                                                                            |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |     Our reorganization not only reduces our cost structure, but also eliminates one layer of management and two layers in the commercial line of business. We believe this will serve to accelerate decision making in the bank, and make us a more disciplined, flexible organization, capable of adapting quickly to changing conditions. We recognize that 2009 will continue to be difficult for our nation, industry, and AMCORE, but have been working steadily towards building an organization that is more streamlined and disciplined to weather a variety of economic circumstances.      |\n",
      "|   |           |                        |               |                           |          |                     |                                                            |                              |              |                |                                                                                                                                                                                          We believe these actions serve the best interests of our shareholders, our customers, our employees, and our business. Now, I would like to turn over the call to Judy for a discussion of our financial stables.                                                                                                                                                                                           |\n",
      "+---+-----------+------------------------+---------------+---------------------------+----------+---------------------+------------------------------------------------------------+------------------------------+--------------+----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "length of all_sentences: 3228275\n"
     ]
    }
   ],
   "source": [
    "corpus = get_corpus('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens before processing: 66,087,551\n",
      "\n",
      "Number of Tokens after processing: 29,573,897\n",
      "Process Sentence Examples:\n",
      "['good', 'morning', 'ladies', 'gentlemen']\n",
      "['welcome', 'amcore', 'financial', 'first', 'quarter', 'earnings', 'result', 'conference', 'call']\n",
      "['time', 'participants', 'listen', 'mode']\n",
      "\n",
      "bigrams created\n",
      "\n",
      "Training the model...\n",
      " Modeling Training Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_corpus = process_the_data(corpus, stop_words)\n",
    "print()\n",
    "phrases, bigram_phraser, corpus_bigrams = create_bigrams(processed_corpus)\n",
    "print()\n",
    "trained_model = apply_word2vec(corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unclear: Similarity = 0.7379\n",
      "severity_duration: Similarity = 0.7350\n",
      "geopolitical_events: Similarity = 0.7257\n",
      "geopolitical_macroeconomic: Similarity = 0.6985\n",
      "lack_clarity: Similarity = 0.6974\n",
      "unsettled: Similarity = 0.6945\n",
      "stressful_economic: Similarity = 0.6929\n",
      "cautious: Similarity = 0.6886\n",
      "remain_cautious: Similarity = 0.6876\n",
      "certainty: Similarity = 0.6868\n",
      "duration_severity: Similarity = 0.6853\n",
      "watchword: Similarity = 0.6850\n",
      "geopolitical_risks: Similarity = 0.6845\n",
      "challenging: Similarity = 0.6818\n",
      "unpredictability: Similarity = 0.6811\n",
      "geopolitical_tensions: Similarity = 0.6805\n",
      "unknown: Similarity = 0.6791\n",
      "depth_duration: Similarity = 0.6777\n",
      "highly_influenced: Similarity = 0.6751\n",
      "clarity_certainty: Similarity = 0.6726\n",
      "fragile: Similarity = 0.6709\n",
      "length_depth: Similarity = 0.6696\n",
      "geopolitical_concerns: Similarity = 0.6680\n",
      "geopolitical_situation: Similarity = 0.6665\n",
      "lingering_impacts: Similarity = 0.6638\n",
      "fragile_nature: Similarity = 0.6638\n",
      "lasting_effects: Similarity = 0.6634\n",
      "broader_macroeconomic: Similarity = 0.6610\n",
      "depth_severity: Similarity = 0.6607\n",
      "caused_covid-19: Similarity = 0.6606\n",
      "covid_variants: Similarity = 0.6589\n",
      "greater_certainty: Similarity = 0.6585\n",
      "rapidly_deteriorating: Similarity = 0.6584\n",
      "fallout_covid-19: Similarity = 0.6562\n",
      "inherently_difficult: Similarity = 0.6554\n",
      "global_macro: Similarity = 0.6548\n",
      "necessitates: Similarity = 0.6534\n",
      "tame_inflation: Similarity = 0.6507\n",
      "stalemate: Similarity = 0.6496\n",
      "macroeconomic_environment: Similarity = 0.6491\n",
      "tenuous: Similarity = 0.6472\n",
      "economic_recovery: Similarity = 0.6469\n",
      "unpredictable_nature: Similarity = 0.6468\n",
      "difficult: Similarity = 0.6465\n",
      "continues_unfold: Similarity = 0.6457\n",
      "element_conservatism: Similarity = 0.6453\n",
      "geopolitical_issues: Similarity = 0.6452\n",
      "debt_ceiling: Similarity = 0.6451\n",
      "unsure: Similarity = 0.6443\n",
      "upcoming_election: Similarity = 0.6439\n",
      "elongating: Similarity = 0.6438\n",
      "determine_ultimate: Similarity = 0.6436\n",
      "stalling: Similarity = 0.6434\n",
      "becomes_clear: Similarity = 0.6422\n",
      "macroeconomic_geopolitical: Similarity = 0.6419\n",
      "depth_recession: Similarity = 0.6417\n",
      "acting_minimize: Similarity = 0.6416\n",
      "economic_geopolitical: Similarity = 0.6404\n",
      "fragile_economy: Similarity = 0.6403\n",
      "depth_length: Similarity = 0.6400\n",
      "length_severity: Similarity = 0.6393\n",
      "electrical_grid: Similarity = 0.6391\n",
      "posed_current: Similarity = 0.6389\n",
      "threat_recession: Similarity = 0.6386\n",
      "stick_fundamentals: Similarity = 0.6385\n",
      "macroeconomic_political: Similarity = 0.6384\n",
      "rollout_covid-19: Similarity = 0.6381\n",
      "clouded: Similarity = 0.6378\n",
      "unpredictable: Similarity = 0.6356\n",
      "geopolitical_instability: Similarity = 0.6351\n",
      "residual_effects: Similarity = 0.6348\n",
      "many_unknowns: Similarity = 0.6339\n",
      "cautious_posture: Similarity = 0.6334\n",
      "political_landscape: Similarity = 0.6327\n",
      "macro_geopolitical: Similarity = 0.6325\n",
      "somewhat_unpredictable: Similarity = 0.6321\n",
      "unable_predict: Similarity = 0.6320\n",
      "slowly_recover: Similarity = 0.6297\n",
      "unknowns: Similarity = 0.6295\n",
      "defensively_positioned: Similarity = 0.6290\n",
      "uneven: Similarity = 0.6289\n",
      "global_geopolitical: Similarity = 0.6284\n",
      "state_flux: Similarity = 0.6282\n",
      "becoming_clearer: Similarity = 0.6273\n",
      "looming_recession: Similarity = 0.6270\n",
      "vaccination_distribution: Similarity = 0.6269\n",
      "pending_regulation: Similarity = 0.6268\n",
      "murky: Similarity = 0.6267\n",
      "loom: Similarity = 0.6267\n",
      "november_elections: Similarity = 0.6265\n",
      "fluid_situation: Similarity = 0.6251\n",
      "economic_environment: Similarity = 0.6242\n",
      "regulatory_climate: Similarity = 0.6238\n",
      "vacillate: Similarity = 0.6238\n",
      "given_newness: Similarity = 0.6236\n",
      "cloudy: Similarity = 0.6233\n",
      "carefully_watching: Similarity = 0.6232\n",
      "pronounced_slowdown: Similarity = 0.6221\n",
      "lingering: Similarity = 0.6208\n",
      "lack_visibility: Similarity = 0.6204\n",
      "difficult_forecast: Similarity = 0.6202\n",
      "persistent_inflation: Similarity = 0.6201\n",
      "stimulus_packages: Similarity = 0.6198\n",
      "post-pandemic_economy: Similarity = 0.6196\n",
      "suspended_buyback: Similarity = 0.6186\n",
      "bumpy_ride: Similarity = 0.6186\n",
      "decoupling: Similarity = 0.6181\n",
      "likely_persist: Similarity = 0.6179\n",
      "sober: Similarity = 0.6173\n",
      "remains_fragile: Similarity = 0.6166\n",
      "economic_political: Similarity = 0.6165\n",
      "fiscal_policy: Similarity = 0.6161\n",
      "drastically_changed: Similarity = 0.6156\n",
      "lengthier: Similarity = 0.6155\n",
      "fight_inflation: Similarity = 0.6147\n",
      "navigate: Similarity = 0.6145\n",
      "faltering: Similarity = 0.6143\n",
      "given_uniqueness: Similarity = 0.6142\n",
      "unable_accurately: Similarity = 0.6135\n",
      "ever-changing: Similarity = 0.6133\n",
      "successfully_navigating: Similarity = 0.6132\n",
      "certainty_around: Similarity = 0.6132\n",
      "crowding: Similarity = 0.6130\n",
      "inflation_geopolitical: Similarity = 0.6130\n",
      "pro-growth_policies: Similarity = 0.6127\n",
      "accurately_predict: Similarity = 0.6122\n",
      "biggest_unknown: Similarity = 0.6117\n",
      "protracted: Similarity = 0.6115\n",
      "slowly_improving: Similarity = 0.6110\n",
      "trade_negotiations: Similarity = 0.6107\n",
      "excessive_government: Similarity = 0.6105\n",
      "severity_recession: Similarity = 0.6104\n",
      "unforeseen_events: Similarity = 0.6091\n",
      "sounder: Similarity = 0.6088\n",
      "post-vaccine: Similarity = 0.6088\n",
      "proving_resilient: Similarity = 0.6083\n",
      "firm_footing: Similarity = 0.6082\n",
      "1-year_horizon: Similarity = 0.6081\n",
      "fluid: Similarity = 0.6078\n",
      "protractive: Similarity = 0.6077\n",
      "somewhat_uneven: Similarity = 0.6077\n",
      "effects_pandemic: Similarity = 0.6075\n",
      "monetary_tightening: Similarity = 0.6074\n",
      "path_virus: Similarity = 0.6074\n",
      "climate: Similarity = 0.6065\n",
      "lack_confidence: Similarity = 0.6057\n",
      "pose_challenges: Similarity = 0.6056\n",
      "rule_writing: Similarity = 0.6053\n",
      "trade_tension: Similarity = 0.6051\n",
      "covid_resurgence: Similarity = 0.6048\n",
      "somewhat_artificially: Similarity = 0.6047\n",
      "adapt_evolving: Similarity = 0.6041\n",
      "constricted: Similarity = 0.6041\n",
      "fed_pursues: Similarity = 0.6039\n",
      "prevail: Similarity = 0.6038\n",
      "presents_challenges: Similarity = 0.6036\n",
      "tried_incorporate: Similarity = 0.6033\n",
      "flux: Similarity = 0.6033\n",
      "challenges_vibrant: Similarity = 0.6033\n",
      "sluggish: Similarity = 0.6026\n",
      "effects_prolonged: Similarity = 0.6026\n",
      "uneven_economic: Similarity = 0.6025\n",
      "short_lived: Similarity = 0.6020\n",
      "persistence: Similarity = 0.6019\n",
      "economic_slowdown: Similarity = 0.6015\n",
      "created_covid-19: Similarity = 0.6013\n",
      "potential_recessionary: Similarity = 0.6011\n",
      "tamper: Similarity = 0.6007\n",
      "miscalculation: Similarity = 0.6005\n",
      "encouraged_resiliency: Similarity = 0.6003\n",
      "mild_moderate: Similarity = 0.6003\n",
      "resiliency_diverse: Similarity = 0.6002\n",
      "watching_developments: Similarity = 0.6000\n",
      "vaccine_deployment: Similarity = 0.6000\n",
      "erred_side: Similarity = 0.5999\n",
      "unclear_exactly: Similarity = 0.5997\n",
      "conjecture: Similarity = 0.5991\n",
      "tunnel: Similarity = 0.5988\n",
      "political_climate: Similarity = 0.5986\n",
      "challenges_posed: Similarity = 0.5985\n",
      "fed_eases: Similarity = 0.5983\n",
      "rollout_vaccine: Similarity = 0.5981\n",
      "economy: Similarity = 0.5978\n",
      "confronting: Similarity = 0.5978\n",
      "omicron_variant: Similarity = 0.5977\n",
      "relatively_tepid: Similarity = 0.5976\n",
      "situation_unfolds: Similarity = 0.5975\n",
      "climates: Similarity = 0.5973\n",
      "consensus_economists: Similarity = 0.5973\n",
      "distortions: Similarity = 0.5971\n",
      "dysfunction: Similarity = 0.5966\n",
      "ultimately_determine: Similarity = 0.5966\n",
      "constructive_dialogues: Similarity = 0.5959\n",
      "economic: Similarity = 0.5953\n",
      "spillover_effects: Similarity = 0.5951\n",
      "society_general: Similarity = 0.5951\n",
      "midterm_elections: Similarity = 0.5950\n",
      "weakened_economy: Similarity = 0.5949\n",
      "borrowing_unforeseen: Similarity = 0.5947\n",
      "deterring: Similarity = 0.5943\n",
      "wait-and-see: Similarity = 0.5934\n",
      "strains: Similarity = 0.5932\n",
      "physical_stimulus: Similarity = 0.5931\n",
      "prolonged: Similarity = 0.5930\n",
      "watchful: Similarity = 0.5929\n",
      "prolonged_disruption: Similarity = 0.5929\n",
      "difficult_determine: Similarity = 0.5929\n",
      "conditions_persist: Similarity = 0.5929\n",
      "trade_disputes: Similarity = 0.5926\n",
      "volatile: Similarity = 0.5926\n",
      "historically_low-rate: Similarity = 0.5925\n",
      "economic_turndown: Similarity = 0.5924\n",
      "aggressive_monetary: Similarity = 0.5922\n",
      "mindful_risks: Similarity = 0.5922\n",
      "challenges_face: Similarity = 0.5922\n",
      "elongation: Similarity = 0.5920\n",
      "taken_arrest: Similarity = 0.5920\n",
      "unchartered_territory: Similarity = 0.5917\n",
      "choppy_waters: Similarity = 0.5917\n",
      "cautious_stance: Similarity = 0.5916\n",
      "stresses_national: Similarity = 0.5916\n",
      "congressional_action: Similarity = 0.5912\n",
      "headwinds_face: Similarity = 0.5909\n",
      "environment: Similarity = 0.5905\n",
      "speed_magnitude: Similarity = 0.5904\n",
      "firm_believers: Similarity = 0.5903\n",
      "clouding: Similarity = 0.5903\n",
      "government_regulation: Similarity = 0.5900\n",
      "elongate: Similarity = 0.5893\n",
      "virus: Similarity = 0.5892\n",
      "curb_inflation: Similarity = 0.5891\n",
      "election_fiscal: Similarity = 0.5890\n",
      "dependent_persistence: Similarity = 0.5886\n",
      "somewhat_episodic: Similarity = 0.5884\n",
      "tightening_monetary: Similarity = 0.5880\n",
      "lot_unknowns: Similarity = 0.5880\n",
      "increasingly_difficult: Similarity = 0.5878\n",
      "adapt_whatever: Similarity = 0.5875\n",
      "becoming_realistic: Similarity = 0.5872\n",
      "economy_softens: Similarity = 0.5872\n",
      "wait-and-see_approach: Similarity = 0.5870\n",
      "choppy: Similarity = 0.5869\n",
      "unprecedented: Similarity = 0.5869\n",
      "knows_exactly: Similarity = 0.5868\n",
      "navigate_ever-changing: Similarity = 0.5868\n",
      "chaotic: Similarity = 0.5867\n",
      "sluggishness_economy: Similarity = 0.5866\n",
      "environmental_challenges: Similarity = 0.5864\n",
      "tempers: Similarity = 0.5861\n",
      "possibility_recession: Similarity = 0.5860\n",
      "somewhat_subdued: Similarity = 0.5859\n",
      "slowing_economy: Similarity = 0.5855\n",
      "fed_tapering: Similarity = 0.5854\n",
      "remain_attentive: Similarity = 0.5853\n",
      "pro-growth_agenda: Similarity = 0.5852\n",
      "regulations_written: Similarity = 0.5850\n",
      "nationally_locally: Similarity = 0.5850\n",
      "vaccines: Similarity = 0.5849\n",
      "elections: Similarity = 0.5848\n",
      "macroeconomic_headwinds: Similarity = 0.5848\n",
      "midst_unprecedented: Similarity = 0.5847\n",
      "indefinite: Similarity = 0.5846\n",
      "unsteady: Similarity = 0.5846\n",
      "plaguing: Similarity = 0.5844\n",
      "fog: Similarity = 0.5842\n",
      "implementation_dodd-frank: Similarity = 0.5840\n",
      "covid_vaccine: Similarity = 0.5838\n",
      "vaccination_rollout: Similarity = 0.5837\n",
      "us-china_relationship: Similarity = 0.5836\n",
      "making_mistakes: Similarity = 0.5834\n",
      "circumstantial: Similarity = 0.5833\n",
      "obstacles: Similarity = 0.5832\n",
      "various_governmental: Similarity = 0.5832\n",
      "persistent_inflationary: Similarity = 0.5830\n",
      "faces_headwinds: Similarity = 0.5824\n",
      "remain_guarded: Similarity = 0.5820\n",
      "fluidity: Similarity = 0.5819\n",
      "step-change: Similarity = 0.5817\n",
      "november_election: Similarity = 0.5814\n"
     ]
    }
   ],
   "source": [
    "similar_words = trained_model.wv.most_similar('uncertain', topn=300)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    if 'uncertain' not in word:\n",
    "        print(f\"{word}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all_sentences: 6456550\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens before processing: 132,175,102\n",
      "\n",
      "Number of Tokens after processing: 76,675,022\n",
      "Process Sentence Example:\n",
      "['good', 'morning', '', 'ladies', 'gentlemen', '']\n",
      "['welcome', 'amcore', 'financial', 'first', 'quarter', 'earnings', 'result', 'conference', 'call', '']\n",
      "['time', '', 'participants', 'listen', 'mode', '']\n"
     ]
    }
   ],
   "source": [
    "sentences = all_sentences\n",
    "\n",
    "flattened_list = [word for sentence in sentences for word in sentence]\n",
    "print(f'Number of Tokens before processing: {len(flattened_list):,}')\n",
    "print()\n",
    "\n",
    "num_tokens = 0\n",
    "processed_sents = []\n",
    "for sent in sentences:\n",
    "   p_sentence = []\n",
    "   for word in sent:\n",
    "     text = word.lower()\n",
    "     if text in stop_words or text == '':\n",
    "        continue\n",
    "     text = re.sub(r'(?<!\\w)-(?!\\w)|[^\\w\\s-]', '', text)\n",
    "     p_sentence.append(text)\n",
    "   processed_sents.append(p_sentence)\n",
    "   num_tokens += len(p_sentence)\n",
    "\n",
    "print(f'Number of Tokens after processing: {num_tokens:,}')\n",
    "print(f'Process Sentence Example:')\n",
    "for i in processed_sents[:3]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'morning', ',', 'ladies', 'and', 'gentlemen', '.']\n",
      "['good', 'morning', '', 'ladies', 'gentlemen', '']\n",
      "\n",
      "['And', 'welcome', 'to', 'the', 'AMCORE', 'Financial', 'first', 'quarter', 'earnings', 'result', 'conference', 'call', '.']\n",
      "['welcome', 'amcore', 'financial', 'first', 'quarter', 'earnings', 'result', 'conference', 'call', '']\n",
      "\n",
      "['At', 'this', 'time', ',', 'participants', 'are', 'in', 'a', 'listen', 'only', 'mode', '.']\n",
      "['time', '', 'participants', 'listen', 'mode', '']\n",
      "\n",
      "['Later', 'we', 'will', 'conduct', 'a', 'question-and-answer', 'session', 'for', 'analysts', 'only', '.']\n",
      "['later', 'conduct', 'question-and-answer', 'session', 'analysts', '']\n",
      "\n",
      "['Please', 'note', 'that', 'this', 'conference', 'is', 'being', 'recorded', '.']\n",
      "['please', 'note', 'conference', 'recorded', '']\n",
      "\n",
      "['This', 'conference', 'call', 'is', 'also', 'being', 'webcast', 'and', 'can', 'be', 'accessed', 'at', 'www.amcore.com', ',', 'and', 'will', 'be', 'archived', 'for', 'additional', 'four', 'weeks', '.']\n",
      "['conference', 'call', 'also', 'webcast', 'accessed', 'wwwamcorecom', '', 'archived', 'additional', 'four', 'weeks', '']\n",
      "\n",
      "['Statements', 'made', 'in', 'the', 'course', 'of', 'this', 'conference', 'call', 'stating', 'the', 'company', '’', 's', 'or', 'management', '’', 's', 'intentions', 'hopes', ',', 'beliefs', ',', 'expectations', ',', 'or', 'predictions', 'of', 'the', 'future', 'are', 'considered', 'forward-looking', 'statements', '.']\n",
      "['statements', 'made', 'course', 'conference', 'call', 'stating', 'company', '', 'management', '', 'intentions', 'hopes', '', 'beliefs', '', 'expectations', '', 'predictions', 'future', 'considered', 'forward-looking', 'statements', '']\n",
      "\n",
      "['It', 'is', 'important', 'to', 'note', 'that', 'the', 'company', '’', 's', 'actual', 'results', 'could', 'differ', 'materially', 'from', 'those', 'projected', 'in', 'such', 'forward-looking', 'statements', '.']\n",
      "['important', 'note', 'company', '', 'actual', 'results', 'could', 'differ', 'materially', 'projected', 'forward-looking', 'statements', '']\n",
      "\n",
      "['Additional', 'information', 'concerning', 'factors', 'that', 'could', 'cause', 'actual', 'result', 'to', 'differ', 'materially', 'from', 'those', 'in', 'the', 'forward-looking', 'statements', ',', 'is', 'contained', 'from', 'time-to-time', 'in', 'the', 'company', \"'s\", 'SEC', 'filings', 'and', 'within', 'the', 'press', 'release', 'itself', '.']\n",
      "['additional', 'information', 'concerning', 'factors', 'could', 'cause', 'actual', 'result', 'differ', 'materially', 'forward-looking', 'statements', '', 'contained', 'time-to-time', 'company', 's', 'sec', 'filings', 'within', 'press', 'release', '']\n",
      "\n",
      "['Conducting', 'the', 'call', 'today', 'will', 'be', 'Mr.', 'William', 'McManaman', ',', 'Chief', 'Executive', 'Officer', ',', 'and', 'Ms.', 'Judith', 'Carre', 'Sutfin', ',', 'Chief', 'Financial', 'Officer', '.']\n",
      "['conducting', 'call', 'today', 'mr', 'william', 'mcmanaman', '', 'chief', 'executive', 'officer', '', 'ms', 'judith', 'carre', 'sutfin', '', 'chief', 'financial', 'officer', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    print(sentences[i])\n",
    "    print(processed_sents[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Your list to be saved\n",
    "\n",
    "# Save the list to a file using pickle\n",
    "with open('my_list.pkl', 'wb') as file:\n",
    "    pickle.dump(processed_sents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec (\n",
    "    vector_size=100,    # Number of features in word vector\n",
    "\n",
    "    window=10,   # Context window size (in each direction). Default is 5\n",
    "\n",
    "\n",
    "    min_count=5, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "\n",
    "    workers=10,  # Training thread count\n",
    "\n",
    "    sg=1,        # 0: CBOW, 1: Skip-gram.\n",
    "\n",
    "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "    negative=5   # Nmber of negative samples\n",
    "                 #   Default is 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(\n",
    "    processed_sents,\n",
    "    progress_per=20000  # Tweaks how often progress is reported\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training the model...')\n",
    "\n",
    "model.train(\n",
    "    processed_sents,\n",
    "    total_examples=len(processed_sents),\n",
    "    epochs=10,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    ")\n",
    "\n",
    "print('  Done.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = model.wv.most_similar('uncertain', topn=150)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(processed_sents, min_count=10, threshold=10, scoring='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
