{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# nltk.download('punkt') # Download the 'punkt' tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import pandas as pd\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "['not', \"that'll\", 'll', 'why', 'that', 'your', 'which', 'couldn', 'hers', 'few', 'doesn', 'am', 'own', 'but', 'very', 'into', 'himself', \"isn't\", \"shan't\", 'for', 'more', \"should've\", 'than', 're', \"mightn't\", 'further', 'here', 'no', 'its', 'over', 'y', 'o', 'under', \"weren't\", 'does', \"she's\", 'as', 'shan', 'didn', 'if', 'out', 'or', 'won', 'against', \"you'd\", 'are', 'only', 'same', 'too', \"hasn't\", 'from', 'his', \"it's\", \"you're\", 'them', 'their', 'weren', \"wouldn't\", \"aren't\", \"needn't\", 'any', 'aren', 'about', 'each', 't', 'were', \"mustn't\", 'there', 'this', 'my', 'once', \"wasn't\", \"shouldn't\", 'nor', 'an', 'a', 'yours', 'above', 'such', 'at', 'don', \"won't\", 'been', 'doing', 'was', 'by', 'should', 'yourselves', 'when', 'have', \"doesn't\", 'in', 'our', 'until', 'themselves', \"haven't\", 'how', 'ourselves', 'off', 'she', 'now', 'm', 'her', 'the', 'ain', 'having', 'before', 'between', 'him', 'down', 'be', 'most', \"don't\", 'after', 'i', 'up', 'some', 'did', \"hadn't\", 'where', 'isn', 'has', 'of', 'what', 'so', 'yourself', 'wasn', 'theirs', 'these', 'all', 'again', 'myself', 'me', 'we', 'on', 'both', 'other', 've', 'to', 'needn', 'shouldn', 'they', 'through', 'who', 'is', 'whom', \"couldn't\", 'mightn', 'itself', 'hasn', 'he', 'and', 'd', 'will', 'hadn', 'ours', 'can', \"didn't\", 'had', 'with', 'do', 'because', 'wouldn', 'mustn', 'just', 'being', 'while', 'during', 'then', 'those', 'ma', \"you've\", 's', \"you'll\", 'it', 'you', 'herself']\n"
=======
      "{'him', 'been', 'such', 'into', 's', 'were', 'who', 'only', 'mightn', 'ours', 'as', 'again', 'so', \"you've\", \"shan't\", 'they', 'do', 'there', 'myself', 're', 'isn', 'below', 'o', 'that', 'had', 'have', 'from', 'very', \"couldn't\", 'until', 't', 'mustn', 'your', 'above', 'at', \"hasn't\", 'weren', 'while', \"that'll\", 'on', \"isn't\", 'other', 'all', 'what', 'their', 'it', 'his', 'or', 'does', 'hasn', \"haven't\", \"wasn't\", 'then', 'both', 'doesn', 'ma', \"wouldn't\", 'some', 'wouldn', 'these', 'he', 'against', 'whom', 'itself', 'and', 'wasn', 'no', 'yourself', 'don', \"aren't\", 'with', 'yourselves', 'further', 'nor', 'are', 'd', \"mustn't\", \"shouldn't\", 'too', 'once', \"don't\", 'our', 'her', 'themselves', 'won', 'under', 'theirs', 'himself', \"you'd\", 'this', 'about', 'why', 'can', 'which', 'we', 'an', 'during', \"mightn't\", 'hers', 'those', 'a', \"doesn't\", 'couldn', 'if', 'you', 'over', 'be', 'has', 'before', 'after', 'off', \"won't\", 'than', 'was', 'in', 'is', 'my', 'ourselves', 'its', 'because', \"should've\", \"needn't\", 'of', 'by', 'each', 'should', 'did', 'any', \"she's\", 'will', \"it's\", 'few', 'she', 'herself', \"weren't\", 'now', \"didn't\", 'down', 'aren', 'not', 'most', 'them', 'haven', 'shan', 'how', 've', 'am', 'between', \"you'll\", \"you're\", 'to', 'ain', 'didn', 'hadn', 'here', 'out', 'shouldn', 'me', 'same', 'where', 'doing', 'being', 'just', 'through', 'yours', 'needn', 'up', 'having', 'the', 'y', 'll', 'i', 'but', 'own', 'm', 'when', 'more', 'for', \"hadn't\"}\n"
>>>>>>> parent of a6a439e (semester 3 start)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "nltk_stop_words = set(stopwords.words('english'))\n",
    "words_to_remove = ['below', 'haven']\n",
    "stop_words = list(filter(lambda word: word not in words_to_remove, nltk_stop_words))\n",
    "print(stop_words)\n",
=======
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> parent of a6a439e (semester 3 start)
    "\n",
    "corpus = brown.sents()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Process Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #list of sentences, each sentence is a list of words\n",
    "\n",
    "def process_the_data(corpus, stop_words):\n",
    "\n",
    "   #count tokens before processing\n",
    "   flattened_list = [word for sentence in corpus for word in sentence]\n",
    "   print(f'Number of Tokens before processing: {len(flattened_list):,}')\n",
    "   print()\n",
    "\n",
    "   num_tokens = 0\n",
    "   processed_sents = []\n",
    "   for sent in corpus:\n",
    "      p_sentence = []\n",
    "      for word in sent:\n",
    "         text = word.lower()                                  #lowercase the text\n",
    "         text = re.sub(r'(?<!\\w)-(?!\\w)|[^\\w\\s-]', '', text)  #remove punctuation but keep hyphens\n",
    "         if text in stop_words or len(text) == 0:             #ignore if word has no length (ie was punctuation only) or in stop words\n",
    "            continue\n",
    "         p_sentence.append(text)\n",
    "      processed_sents.append(p_sentence)\n",
    "      num_tokens += len(p_sentence)\n",
    "\n",
    "   #count tokens after processing\n",
    "   print(f'Number of Tokens after processing: {num_tokens:,}')\n",
    "   print(f'Process Sentence Examples:')\n",
    "   for i in processed_sents[:3]:\n",
    "      print(i)\n",
    "\n",
    "   return processed_sents\n",
    "\n",
    "def create_bigrams(processed_corpus):\n",
    "   phrases = Phrases(processed_corpus, min_count=2, threshold=10, scoring='default')\n",
    "   bigram_phraser = Phraser(phrases)\n",
    "\n",
    "   corpus_bigrams = [bigram_phraser[sentence] for sentence in processed_corpus]\n",
    "\n",
    "   print('bigrams created')\n",
    "\n",
    "   return phrases, bigram_phraser, corpus_bigrams\n",
    "\n",
    "def apply_word2vec(corpus_bigrams):\n",
    "   model = gensim.models.Word2Vec (\n",
    "    vector_size=100,    # Number of features in word vector\n",
    "\n",
    "    window=10,   # Context window size (in each direction). Default is 5\n",
    "\n",
    "\n",
    "    min_count=5, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "\n",
    "    workers=10,  # Training thread count\n",
    "\n",
    "    sg=1,        # 0: CBOW, 1: Skip-gram.\n",
    "\n",
    "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "    negative=5   # Nmber of negative samples\n",
    "                 #   Default is 5\n",
    "   )\n",
    "\n",
    "   model.build_vocab(\n",
    "    corpus_bigrams,\n",
    "    progress_per=20000  # Tweaks how often progress is reported\n",
    "   )\n",
    "\n",
    "   print('Training the model...')\n",
    "\n",
    "   model.train(\n",
    "    corpus_bigrams,\n",
    "    total_examples=len(corpus_bigrams),\n",
    "    epochs=10,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    "   )\n",
    "\n",
    "   print(' Modeling Training Done.')\n",
    "   print('')\n",
    "\n",
    "   return(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
=======
   "execution_count": 22,
>>>>>>> parent of a6a439e (semester 3 start)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens before processing: 1,161,192\n",
      "\n",
      "Number of Tokens after processing: 540,078\n",
      "Process Sentence Examples:\n",
      "['fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', 'atlantas', 'recent', 'primary', 'election', 'produced', 'evidence', 'irregularities', 'took', 'place']\n",
      "['jury', 'said', 'term-end', 'presentments', 'city', 'executive', 'committee', 'over-all', 'charge', 'election', 'deserves', 'praise', 'thanks', 'city', 'atlanta', 'manner', 'election', 'conducted']\n",
      "['september-october', 'term', 'jury', 'charged', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'investigate', 'reports', 'possible', 'irregularities', 'hard-fought', 'primary', 'mayor-nominate', 'ivan', 'allen', 'jr']\n",
      "\n",
      "\n",
      "Training the model...\n",
      " Modeling Training Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_corpus = process_the_data(corpus, stop_words)\n",
    "print()\n",
    "phrases, bigram_phraser, corpus_bigrams = create_bigrams(processed_corpus)\n",
    "print()\n",
    "trained_model = apply_word2vec(corpus_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 23,
>>>>>>> parent of a6a439e (semester 3 start)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "disturbing: Similarity = 0.9060\n",
      "catharsis: Similarity = 0.8967\n",
      "paralysis: Similarity = 0.8948\n",
      "experimenter: Similarity = 0.8937\n",
      "assures: Similarity = 0.8895\n",
      "whatsoever: Similarity = 0.8894\n",
      "devoid: Similarity = 0.8888\n",
      "connotation: Similarity = 0.8887\n",
      "contradictions: Similarity = 0.8884\n",
      "schizophrenic: Similarity = 0.8862\n"
=======
      "['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
      "['jury', 'said', 'termend', 'presentments', 'city', 'executive', 'committee', 'overall', 'charge', 'election', 'deserves', 'praise', 'thanks', 'city', 'atlanta', 'manner', 'election', 'conducted']\n"
>>>>>>> parent of a6a439e (semester 3 start)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "similar_words = trained_model.wv.most_similar('uncertain', topn=10)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phraser object: FrozenPhrases<615 phrases, min_count=10, threshold=1>\n",
      "\n",
      "Attributes of the Phraser object:\n",
      "add_lifecycle_event\n",
      "analyze_sentence\n",
      "connector_words\n",
      "delimiter\n",
      "find_phrases\n",
      "lifecycle_events\n",
      "load\n",
      "min_count\n",
      "phrasegrams\n",
      "save\n",
      "score_candidate\n",
      "scoring\n",
      "threshold\n",
      "\n",
      "Transformed sentence: ['new_york', 'is', 'a', 'great', 'place']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(\"Phraser object:\", bigram)\n",
    "\n",
    "# # Print attributes of the Phraser object\n",
    "# print(\"\\nAttributes of the Phraser object:\")\n",
    "# for attr in dir(bigram):\n",
    "#     if not attr.startswith('_'):\n",
    "#         print(attr)\n",
    "\n",
    "# # Apply the Phraser to a sentence\n",
    "# sentence = ['new', 'york', 'is', 'a', 'great', 'place']\n",
    "# print(\"\\nTransformed sentence:\", bigram[sentence])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contents of the 'phrasegrams' dictionary:\n",
      "took_place: 15.135095955852073\n",
      "superior_court: 86.84083175803403\n",
      "city_council: 34.04639442673979\n",
      "one_two: 3.157737182312704\n",
      "must_taken: 3.227705311379118\n",
      "per_cent: 1086.4580123467526\n",
      "public_relations: 30.847972065538546\n",
      "three_years: 18.056225741471643\n",
      "every_time: 4.683940465296488\n",
      "10_per: 14.151343858298036\n",
      "per_day: 19.826300529274903\n",
      "set_aside: 66.24673732785348\n",
      "public_education: 29.406478043784407\n",
      "would_like: 5.240434303496833\n",
      "ever_saw: 7.565678524374176\n",
      "school_board: 11.696504196830947\n",
      "little_doubt: 19.396964131146156\n",
      "million_dollars: 229.7859143657463\n",
      "fiscal_year: 279.2632218844985\n",
      "personal_property: 105.17124542124542\n",
      "said_would: 1.8989559490386785\n",
      "years_age: 4.043427937701066\n",
      "school_districts: 147.12971068645246\n",
      "five_years: 40.11617752876494\n",
      "real_estate: 698.2641738866089\n",
      "attorney_general: 269.64386777880753\n",
      "supreme_court: 704.9432225063939\n",
      "could_make: 3.9752138540616144\n",
      "de_la: 439.3054644808743\n",
      "high_school: 119.75216077290908\n",
      "would_require: 5.904628883823756\n",
      "rhode_island: 2122.066039349872\n",
      "high_schools: 23.29459251145998\n",
      "new_york: 266.0853595803714\n",
      "york_city: 65.80048194395295\n",
      "depend_upon: 20.62347923681257\n",
      "president_kennedy: 257.69708302169033\n",
      "white_house: 123.51715921470459\n",
      "american_people: 11.4383983168134\n",
      "would_say: 6.381060579476203\n",
      "even_greater: 2.088507001272959\n",
      "st_louis: 832.7732366512854\n",
      "social_security: 92.99352226720647\n",
      "last_year: 70.22891674610169\n",
      "per_year: 7.5273105629244865\n",
      "first_year: 2.564871619071441\n",
      "would_go: 6.489432383499592\n",
      "10_years: 5.24490366776081\n",
      "would_still: 1.0822636061569544\n",
      "president_said: 1.2265031998312645\n",
      "young_people: 7.043775586868857\n",
      "would_provide: 4.7018341111929915\n",
      "vocational_rehabilitation: 271.18536009445097\n",
      "sam_rayburn: 2385.656604998377\n",
      "president_kennedys: 185.01329037454693\n",
      "much_better: 8.289679777684976\n",
      "long_time: 11.453260799106454\n",
      "weeks_ago: 98.93673612232811\n",
      "general_assembly: 166.04385542168674\n",
      "united_states: 565.9871305458028\n",
      "secretary_state: 50.66658881384742\n",
      "may_also: 5.21078133736517\n",
      "three_days: 20.658468582641756\n",
      "foreign_policy: 275.0355798836812\n",
      "soviet_union: 332.6346366811483\n",
      "take_place: 29.06682772505033\n",
      "kennedy_administration: 142.66708074534162\n",
      "first_time: 12.039809129523587\n",
      "state_department: 35.420250585157646\n",
      "viet_nam: 6625.788461538462\n",
      "would_become: 5.657917370572068\n",
      "free_world: 24.791216338865638\n",
      "question_whether: 62.50006802535985\n",
      "latin_america: 142.07876288659793\n",
      "mr_nixon: 21.771943127962086\n",
      "thus_far: 13.825328036595641\n",
      "southeast_asia: 1080.0658307210033\n",
      "one_time: 2.3542234890974956\n",
      "government_united: 36.48180428438127\n",
      "could_find: 7.890799500312306\n",
      "called_upon: 4.628711050656188\n",
      "development_program: 24.43627465880422\n",
      "civil_defense: 120.91544383759953\n",
      "federal_government: 49.142918271287975\n",
      "would_come: 4.2988197588050205\n",
      "several_years: 15.825140376864514\n",
      "years_ago: 238.7923621094353\n",
      "last_night: 77.71216113102695\n",
      "would_expect: 7.836390185321651\n",
      "general_public: 12.636518677449525\n",
      "young_man: 36.57744542119024\n",
      "vice_president: 527.964755459073\n",
      "told_us: 1.3273503730200467\n",
      "turned_back: 8.916692546583851\n",
      "first_step: 20.612952981361932\n",
      "left_hand: 2.220552977571539\n",
      "right_hand: 5.216307157753697\n",
      "last_week: 101.31741796664873\n",
      "district_court: 59.180418679549106\n",
      "new_jersey: 101.14965137614679\n",
      "income_tax: 83.87201606645671\n",
      "recent_years: 38.45774337394449\n",
      "economic_development: 39.62095561962495\n",
      "come_back: 15.097045581517632\n",
      "one_side: 9.508435649365486\n",
      "york_times: 55.22335147422027\n",
      "national_defense: 7.3355369261477055\n",
      "peace_corps: 949.1487603305785\n",
      "premier_khrushchev: 1299.1742081447962\n",
      "mr_khrushchev: 40.02195427934207\n",
      "united_nations: 186.18446395831324\n",
      "would_take: 6.104676419778441\n",
      "would_get: 2.0339042083131234\n",
      "new_orleans: 217.11415068112316\n",
      "district_columbia: 378.09711934156377\n",
      "years_old: 15.968787642010033\n",
      "department_justice: 53.729590643274854\n",
      "armed_forces: 783.0477272727272\n",
      "air_force: 132.1197090170868\n",
      "puerto_rico: 10026.325396825396\n",
      "virgin_islands: 984.4028571428572\n",
      "sales_tax: 51.55291213107395\n",
      "even_though: 59.788259518259515\n",
      "could_tell: 12.847977476763589\n",
      "go_home: 13.415843608179381\n",
      "far_less: 4.935357376908284\n",
      "press_conference: 75.35892388451444\n",
      "district_attorney: 104.70381766381766\n",
      "wide_variety: 85.78674136321195\n",
      "two_years: 18.20115295469403\n",
      "kansas_city: 527.9021587457933\n",
      "could_take: 2.822342593256264\n",
      "feet_away: 7.119645403260803\n",
      "economic_affairs: 45.01156182637664\n",
      "way_life: 13.42960757614223\n",
      "make_sure: 46.197948492017126\n",
      "los_angeles: 7206.086274509804\n",
      "would_make: 6.608623259560929\n",
      "school_system: 6.719866593852395\n",
      "would_done: 1.061229015692462\n",
      "new_testament: 38.7546556996731\n",
      "jesus_christ: 1092.913560666138\n",
      "first_two: 6.215272472956687\n",
      "new_england: 71.15505778625044\n",
      "last_two: 2.887682920696649\n",
      "two_days: 8.11335683454254\n",
      "late_afternoon: 48.422894487193\n",
      "three_weeks: 4.987384648789491\n",
      "two_hours: 14.788436775688902\n",
      "san_francisco: 4641.899651567944\n",
      "saturday_night: 100.09543523259615\n",
      "didnt_get: 3.059027997429657\n",
      "three_times: 34.79647243412866\n",
      "years_later: 24.27584506173927\n",
      "dont_know: 79.7770691673628\n",
      "30_minutes: 167.89815228426397\n",
      "next_week: 12.719556991232118\n",
      "back_home: 1.738782215055961\n",
      "came_back: 16.82034178133717\n",
      "im_going: 75.36098427887902\n",
      "dont_think: 39.05308944586917\n",
      "home_runs: 229.04503905600797\n",
      "living_room: 147.99871134020617\n",
      "two_men: 14.924110507575955\n",
      "four_years: 20.396847596847596\n",
      "long_island: 7.306311679429984\n",
      "couple_weeks: 24.936923243947454\n",
      "one_way: 2.2992599532928724\n",
      "year_ago: 8.514122618429832\n",
      "several_times: 36.194132941145575\n",
      "dont_worry: 136.64636549544525\n",
      "ive_never: 10.545492109038737\n",
      "never_seen: 21.261072800481326\n",
      "old_man: 32.82054380210246\n",
      "early_days: 3.130070997369963\n",
      "mr_mrs: 38.66045975993267\n",
      "hong_kong: 3796.595041322314\n",
      "around_world: 4.154594003083922\n",
      "come_along: 8.216194947462553\n",
      "way_back: 1.0463298917883506\n",
      "post_office: 148.3605997693195\n",
      "several_months: 18.651058301304605\n",
      "advisory_board: 80.08856345885634\n",
      "mrs_robert: 10.345411552753069\n",
      "several_days: 15.193713329408576\n",
      "dining_room: 341.8065476190476\n",
      "washington_dc: 278.754854368932\n",
      "back_forth: 87.073805149739\n",
      "july_1: 76.48817848817849\n",
      "six_weeks: 27.657314870559905\n",
      "world_war: 67.93298427025368\n",
      "war_2: 57.48737486095662\n",
      "national_park: 39.09685106382979\n",
      "may_made: 2.038811856078618\n",
      "well_known: 7.804591305825139\n",
      "last_years: 6.78889158179099\n",
      "police_said: 3.0227369182938264\n",
      "number_years: 1.9446147073265716\n",
      "six_years: 8.344164925983108\n",
      "six_months: 85.22968460111316\n",
      "three_four: 20.919307832422586\n",
      "research_development: 88.47687081976397\n",
      "young_men: 31.276948477472725\n",
      "ever_since: 38.16571586818056\n",
      "first_day: 2.9479223150201017\n",
      "side_side: 12.658716872989302\n",
      "one_another: 8.555667299884531\n",
      "would_allow: 2.3509170555964958\n",
      "two_weeks: 49.55595369866612\n",
      "never_knew: 8.342952617910393\n",
      "court_order: 5.312072155411656\n",
      "least_one: 8.53072366344172\n",
      "roman_catholic: 754.3316912972085\n",
      "board_trustees: 137.2946802151823\n",
      "white_people: 1.4859471785997316\n",
      "higher_education: 133.33372032274917\n",
      "set_forth: 156.286316935429\n",
      "war_1: 7.2531893393962354\n",
      "five_minutes: 138.6105569557346\n",
      "minutes_later: 46.99080668465266\n",
      "million_acres: 51.17959001782531\n",
      "collective_bargaining: 797.5486111111111\n",
      "many_years: 13.366866143565172\n",
      "one_night: 3.0511347409390086\n",
      "next_year: 5.315924274451113\n",
      "half_hour: 103.6863197492163\n",
      "probably_would: 1.2970576858463423\n",
      "three_months: 11.526965540314487\n",
      "could_get: 8.044995242459445\n",
      "get_back: 5.079379821819016\n",
      "never_done: 2.0661230621157403\n",
      "nuclear_weapons: 851.3248752672844\n",
      "nuclear_war: 51.65532233883059\n",
      "many_cases: 11.973362872222584\n",
      "able_get: 2.8395144142807696\n",
      "many_men: 1.1690898217307766\n",
      "interest_rates: 95.53523469994059\n",
      "west_berlin: 211.3343300747556\n",
      "looked_like: 22.283269079896407\n",
      "also_used: 2.813330291705389\n",
      "york_central: 46.09552478426651\n",
      "two_three: 14.933896809548134\n",
      "gross_income: 510.8568251320545\n",
      "black_white: 6.1999865038126725\n",
      "fine_arts: 41.96090610157106\n",
      "go_back: 15.95318794276983\n",
      "men_women: 89.54028967973923\n",
      "miles_away: 17.469881350775783\n",
      "one_might: 3.110159668963127\n",
      "feel_like: 6.584508657264075\n",
      "past_year: 2.48454823740657\n",
      "eighteenth_century: 385.959252257929\n",
      "one_day: 8.721123124149297\n",
      "second_half: 22.273357575757576\n",
      "christian_faith: 57.48098098098098\n",
      "ever_seen: 52.49875850605164\n",
      "must_also: 1.2726639745054238\n",
      "get_along: 3.455409090054345\n",
      "going_get: 1.5371807355504918\n",
      "feet_long: 6.467247617304633\n",
      "work_done: 9.449394844453222\n",
      "could_hear: 26.255779680183544\n",
      "many_times: 23.55156525361274\n",
      "im_sure: 38.11030763912893\n",
      "george_washington: 17.28712275156168\n",
      "come_home: 3.999199094628711\n",
      "much_time: 3.681667185369118\n",
      "young_woman: 5.326855287569573\n",
      "attitude_toward: 166.8398624763934\n",
      "mr_kennedy: 93.30832769126607\n",
      "3_4: 58.141180193007436\n",
      "cold_war: 86.84739866908652\n",
      "new_ones: 3.1046547383716017\n",
      "would_give: 5.656705306011105\n",
      "make_clear: 7.925675442531314\n",
      "two_months: 1.6599265768630398\n",
      "throughout_world: 24.839168401416636\n",
      "could_hardly: 18.94874665598152\n",
      "perhaps_even: 1.2789554274896295\n",
      "american_catholic: 9.611431918989037\n",
      "one_thing: 20.92119416960181\n",
      "would_seem: 20.696282899923734\n",
      "faculty_members: 94.92272088602364\n",
      "first_place: 11.843407195431636\n",
      "may_seem: 8.585140379619881\n",
      "antitrust_laws: 773.3804713804714\n",
      "let_us: 75.66242790373906\n",
      "short_time: 8.136137152572791\n",
      "dont_get: 1.2542640357559227\n",
      "public_interest: 22.247931368479314\n",
      "whole_world: 3.778125938079553\n",
      "man_could: 2.377283874463299\n",
      "new_members: 18.044025474847796\n",
      "next_morning: 88.41398224553132\n",
      "could_see: 30.849569407721212\n",
      "period_time: 10.848182870097055\n",
      "one_man: 2.1933454102911463\n",
      "ten_years: 75.5553958236885\n",
      "blue_eyes: 48.06738398758349\n",
      "dont_want: 48.690682827073665\n",
      "youve_got: 156.47699263020993\n",
      "every_day: 25.875873436559676\n",
      "looks_like: 45.58505993490513\n",
      "didnt_know: 48.64212820803044\n",
      "last_time: 2.126308032970207\n",
      "wall_street: 11.767110655737705\n",
      "western_europe: 28.41692440925399\n",
      "large_enough: 2.9594021774141597\n",
      "much_less: 10.097203939736586\n",
      "may_find: 2.4574964336661913\n",
      "great_britain: 12.560164046479835\n",
      "civil_war: 348.15308829101934\n",
      "status_quo: 430.54170571696346\n",
      "secretary_treasury: 481.034554973822\n",
      "economic_social: 9.949924193199047\n",
      "twenty_minutes: 29.148984771573605\n",
      "get_away: 5.380132574426721\n",
      "made_clear: 1.8645885337392187\n",
      "long_enough: 15.606621575712653\n",
      "take_time: 1.885094072508669\n",
      "trying_get: 15.051168429071073\n",
      "im_sorry: 139.20848484848486\n",
      "cents_per: 47.624714907733775\n",
      "per_capita: 464.34097035040435\n",
      "western_world: 8.52146653187286\n",
      "might_well: 14.938475546305932\n",
      "look_like: 23.16954926014727\n",
      "one_must: 1.5130174579121707\n",
      "could_easily: 2.681665080819815\n",
      "sounds_like: 6.464790318041092\n",
      "great_deal: 159.41746674378254\n",
      "would_appear: 7.233590940296909\n",
      "people_would: 1.199050965782392\n",
      "common_sense: 39.74345738468415\n",
      "would_happen: 2.686762349253138\n",
      "good_deal: 67.75751791632685\n",
      "one_greatest: 1.583354013290319\n",
      "time_time: 4.317549627898452\n",
      "could_go: 2.291838367793292\n",
      "large_part: 10.18034349030471\n",
      "far_beyond: 6.162146210596915\n",
      "every_year: 1.4219104983935769\n",
      "closed_eyes: 43.23041452971345\n",
      "go_far: 5.167934122305719\n",
      "secretary_general: 33.80764944595135\n",
      "four_five: 4.461810411810411\n",
      "human_beings: 682.8509847640282\n",
      "tax_collection: 108.83392561004501\n",
      "taken_place: 2.86812761440969\n",
      "may_well: 4.773492899247544\n",
      "dependent_upon: 46.40282828282828\n",
      "one_best: 1.5878649933851634\n",
      "old_woman: 9.307893883725956\n",
      "could_never: 4.116759880168152\n",
      "man_must: 1.1271564115545138\n",
      "mr_podger: 233.2708192281652\n",
      "early_morning: 29.743091704866238\n",
      "would_never: 6.55693365291189\n",
      "hes_got: 7.624697095435685\n",
      "big_man: 7.400616772530609\n",
      "dont_see: 6.084480328893692\n",
      "would_look: 1.2726769022778022\n",
      "might_even: 1.1685693935693937\n",
      "washington_25: 22.52564479748946\n",
      "hundred_yards: 125.92872807017544\n",
      "didnt_even: 2.9374512436856577\n",
      "cities_towns: 469.5846962616822\n",
      "still_another: 6.870791642362513\n",
      "would_want: 1.0321099268472418\n",
      "almost_every: 17.326242739684695\n",
      "prime_minister: 1506.1901639344262\n",
      "many_people: 10.00489678018363\n",
      "east_greenwich: 650.822910342036\n",
      "life_death: 4.638994218777612\n",
      "based_upon: 54.59156268568033\n",
      "away_home: 3.683472850315918\n",
      "know_much: 1.435652553006308\n",
      "general_motors: 591.7705539137683\n",
      "step_toward: 27.254756160265792\n",
      "point_view: 106.29639308561318\n",
      "declaration_independence: 273.4452380952381\n",
      "one_hundred: 15.481683685505342\n",
      "would_probably: 2.5941153716926846\n",
      "international_law: 79.29882403711295\n",
      "station_wagon: 556.8339393939394\n",
      "must_take: 2.9737219426148593\n",
      "editor_inquirer: 1376.7872127872129\n",
      "vocational_training: 76.48817848817849\n",
      "first_half: 3.682222964397836\n",
      "weve_got: 28.03197461557237\n",
      "many_ways: 3.4574245503123353\n",
      "across_river: 19.74588437567161\n",
      "strong_enough: 5.2888326041906515\n",
      "let_go: 38.22117944621938\n",
      "didnt_like: 1.773383877766883\n",
      "human_life: 15.041822391655169\n",
      "human_race: 74.58323862713901\n",
      "one_hand: 8.405368868696636\n",
      "large_number: 40.44098314474858\n",
      "everything_else: 42.32690417690418\n",
      "social_economic: 54.72458306259476\n",
      "half_dozen: 64.25006993006993\n",
      "almost_always: 6.965490053372149\n",
      "great_many: 4.694818599897803\n",
      "far_end: 5.273230253567042\n",
      "much_greater: 5.215695179272918\n",
      "one_finds: 2.3616127655855608\n",
      "one_cannot: 2.700293666076513\n",
      "next_day: 32.246329587184775\n",
      "give_us: 5.636973820640404\n",
      "college_university: 24.119920193216423\n",
      "table_1: 55.241462241462244\n",
      "something_like: 6.321128310973512\n",
      "du_pont: 4436.7452716297785\n",
      "matter_fact: 23.357128330282695\n",
      "twenty_years: 28.683066933066932\n",
      "man_whose: 6.065388817554966\n",
      "one_could: 1.392481230926152\n",
      "boys_girls: 36.82764149430816\n",
      "could_write: 2.70696380799736\n",
      "quite_different: 10.479697052650788\n",
      "ten_minutes: 71.09508480871611\n",
      "nineteenth_century: 1268.151828847481\n",
      "takes_place: 28.114320685434517\n",
      "long_way: 1.342303685879876\n",
      "man_woman: 5.097363593324654\n",
      "something_else: 63.80388888888889\n",
      "ive_got: 182.99273029045645\n",
      "early_years: 3.7617136961399256\n",
      "st_john: 139.28351974127474\n",
      "three_men: 2.96105536815418\n",
      "says_dr: 35.8896875\n",
      "hydrogen_atoms: 574.5941213258286\n",
      "social_life: 3.3815826278984176\n",
      "national_forest: 148.4890505050505\n",
      "feet_high: 3.259596690649524\n",
      "fat_man: 6.3433858050262355\n",
      "middle_class: 36.20649432534678\n",
      "two_hundred: 19.026059009658233\n",
      "hundred_years: 40.25693604640973\n",
      "straight_line: 27.04509596137996\n",
      "word_god: 5.30569158274046\n",
      "fifty_years: 26.995827701710056\n",
      "gives_us: 9.617468492232968\n",
      "lo_shu: 10937.809523809523\n",
      "many_things: 7.271865766146052\n",
      "front_door: 79.94918203967978\n",
      "twentieth_century: 443.85314009661835\n",
      "would_better: 1.226565420311215\n",
      "south_america: 9.866580756013747\n",
      "forty_years: 25.496059496059495\n",
      "states_america: 76.50394924662966\n",
      "know_whether: 4.703519028555632\n",
      "three_hundred: 4.404064806825807\n",
      "went_back: 14.069731828929154\n",
      "new_birth: 29.799981466036513\n",
      "1_st: 5.130304654694899\n",
      "born_god: 51.460513050296846\n",
      "open_door: 37.04144492823738\n",
      "fifteen_years: 32.780647923505065\n",
      "never_heard: 2.66839375228713\n",
      "one_year: 2.1175555192940436\n",
      "thirty_years: 70.00612946375658\n",
      "room_temperature: 8.861651234567901\n",
      "ballistic_missile: 562.9754901960785\n",
      "dont_care: 23.196142290893484\n",
      "red_river: 28.265682202738038\n",
      "fig_1: 34.576847809724526\n",
      "fig_7: 188.7895890410959\n",
      "shown_fig: 189.54778016174285\n",
      "2_3: 10.080930436690807\n",
      "af_af: 47.23469782745439\n",
      "across_street: 40.05824904080921\n",
      "either_side: 16.982292706369453\n",
      "dont_forget: 17.397106718170114\n",
      "first_thing: 4.054499760598217\n",
      "john_brown: 64.89345806127574\n",
      "someone_else: 55.535299806576404\n",
      "make_possible: 3.0939802529667695\n",
      "hot_water: 23.823059636992223\n",
      "youre_going: 30.499294594101148\n",
      "drugs_chemical: 1191.0059259259258\n",
      "chemical_name: 208.3392290249433\n",
      "milligrams_per: 117.92786548581695\n",
      "per_head: 29.203834613232978\n",
      "per_pound: 265.33769734308817\n",
      "interior_design: 272.27833096254153\n",
      "number_people: 4.59636203549917\n",
      "turned_away: 22.037527412280703\n",
      "national_forests: 222.73357575757575\n",
      "nothing_else: 31.753760230037603\n",
      "du_ponts: 2156.7511737089203\n",
      "long_ago: 37.199818611731935\n",
      "middle_ages: 73.83285117325619\n",
      "want_see: 1.8142139517250095\n",
      "shook_head: 456.1946375372393\n",
      "science_fiction: 152.4686359110521\n",
      "main_street: 31.64265050282408\n",
      "good_luck: 12.126814846101052\n",
      "id_like: 9.969069182025983\n",
      "take_care: 46.48735073871686\n",
      "want_go: 13.424024000623392\n",
      "anything_else: 93.21996753246754\n",
      "closely_related: 136.47890671420083\n",
      "said_mr: 1.1102469723591069\n",
      "brooklyn_college: 237.3178354642903\n",
      "business_administration: 14.520822467719247\n",
      "didnt_think: 2.6457413049362737\n",
      "mary_jane: 1206.9307060755336\n",
      "vocational_education: 250.9098191528098\n",
      "ill_get: 25.09098191528098\n",
      "thousand_dollars: 96.65221965074689\n",
      "unwed_mothers: 588.9589743589744\n",
      "economic_integration: 196.9255829903978\n",
      "didnt_want: 69.85402347789064\n",
      "less_developed: 6.183712478126262\n",
      "could_think: 1.9880242285061445\n",
      "human_nature: 16.08811220648234\n",
      "didnt_seem: 20.01058489148308\n",
      "mr_justice: 23.872744657853165\n",
      "private_detective: 323.7732581554571\n",
      "private_eye: 78.85812376620032\n",
      "shown_figure: 105.92909436790222\n",
      "figure_1: 4.025693604640973\n",
      "figure_2: 42.54249112517363\n",
      "social_system: 2.9060475708502023\n",
      "figure_3: 14.952576245809329\n",
      "look_back: 2.383744039186994\n",
      "anything_like: 1.2698695267580717\n",
      "knew_would: 2.1426079494044012\n",
      "said_nothing: 2.2799232230440056\n",
      "mrs_coolidge: 363.2831056793674\n",
      "would_turn: 1.452927278995259\n",
      "somebody_else: 90.00548589341692\n",
      "felt_like: 5.975856596508573\n",
      "saxon_shore: 836.7723132969035\n",
      "know_something: 2.989347649259802\n",
      "article_2: 14.528399746995573\n",
      "could_feel: 3.9852522728850026\n",
      "small_business: 66.85740307784758\n",
      "business_concerns: 54.368660867506954\n",
      "motor_pool: 73.9041184041184\n",
      "table_2: 14.968654284783318\n",
      "planning_division: 66.56350068825618\n",
      "fiscal_years: 19.122044622044623\n",
      "june_30: 185.61131313131312\n",
      "uniform_fiscal: 75.06339869281045\n",
      "john_notte: 317.25690607734805\n",
      "notte_jr: 1531.2933333333335\n",
      "jr_governor: 295.1890763052209\n",
      "shall_made: 4.571024875621891\n",
      "calendar_year: 74.80264871906209\n",
      "government_india: 151.5881867678601\n",
      "capita_income: 1053.6422018348624\n",
      "result_obtained: 32.7432644333571\n",
      "obtained_item: 145.2610276679842\n",
      "1_2: 37.997353184449956\n",
      "general_business: 4.694482765668271\n",
      "business_activity: 20.153900149162062\n",
      "local_board: 20.022140864714085\n",
      "appeal_board: 183.05957362024307\n",
      "exportimport_bank: 1581.3700516351118\n",
      "class_1: 8.090095801634263\n",
      "see_chapter: 24.454609979416567\n",
      "brown_sharpe: 1131.0689393939392\n",
      "mr_brown: 9.277816673847479\n",
      "radio_emission: 717.79375\n",
      "anode_holder: 1988.6926406926407\n",
      "af_bond: 30.08040859088528\n",
      "order_af: 4.906733316243699\n",
      "carbon_tetrachloride: 6447.550877192983\n",
      "pulmonary_artery: 2219.2657004830917\n",
      "bronchial_artery: 1721.8440779610196\n",
      "sweet_clover: 2496.673913043478\n",
      "nonspecific_staining: 2613.8719772403983\n",
      "hypothalamic_balance: 696.0424242424242\n",
      "minimal_polynomial: 3645.936507936508\n",
      "c_af: 18.954778016174288\n",
      "information_cell: 210.18610237346297\n",
      "cell_af: 14.191782514674081\n",
      "dominant_stress: 1387.0809489575845\n",
      "strong_stress: 21.254187100953086\n",
      "wage_rate: 549.5071770334928\n",
      "basic_wage: 335.8099415204678\n",
      "federal_courts: 32.19708438463695\n",
      "school_desegregation: 69.8866125760649\n",
      "opened_door: 89.91740066549227\n",
      "utopian_communism: 625.0176870748298\n",
      "providence_daily: 141.20532786885246\n",
      "index_words: 289.7824637289358\n",
      "words_electronic: 73.96758265349936\n",
      "electronic_switches: 2078.6787330316743\n",
      "index_word: 227.68622150130668\n",
      "word_electronic: 49.311721768999575\n",
      "electronic_switch: 628.437756497948\n",
      "oxidation_pond: 2396.8069565217393\n",
      "oxygen_transfer: 267.7086247086247\n",
      "urethane_foam: 477.53430353430355\n",
      "urethane_foams: 1536.4147157190635\n",
      "wash_wheel: 443.42471042471044\n",
      "optimal_policy: 369.520592020592\n",
      "objective_function: 44.67451132937858\n",
      "looked_around: 13.363755369592832\n",
      "simms_purdew: 4503.803921568628\n",
      "big_hans: 56.71456790123457\n",
      "linda_kay: 3645.936507936508\n",
      "bobby_joe: 1815.7628458498023\n",
      "oh_yes: 78.4474043715847\n",
      "miss_ada: 523.6981304149567\n",
      "mr_jack: 11.832577786935916\n",
      "door_open: 4.630180616029673\n",
      "mr_skyros: 296.8901335631193\n",
      "blue_throat: 62.99026463732346\n",
      "miss_langford: 791.3660637381568\n",
      "mike_deegan: 458.9290709290709\n"
     ]
    }
   ],
   "source": [
    "# phrasegrams = bigram.__dict__.get('phrasegrams', None)\n",
    "# if phrasegrams:\n",
    "#     print(\"\\nContents of the 'phrasegrams' dictionary:\")\n",
    "#     for phrase, count in phrasegrams.items():\n",
    "#         print(f\"{phrase}: {count}\")\n",
    "\n",
    "phrase_vocab = phrases.vocab\n",
    "sorted_phrases = sorted(phrase_vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "for phrase, count in sorted_phrases:\n",
    "    if count > 100 and \"_\" in phrase:\n",
    "        print(phrase, count)"
=======
    "#check processing\n",
    "print(sentences[1])\n",
    "print(processed_sents[1])"
>>>>>>> parent of a6a439e (semester 3 start)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec (\n",
    "    vector_size=100,    # Number of features in word vector\n",
    "\n",
    "    window=10,   # Context window size (in each direction). Default is 5\n",
    "\n",
    "\n",
    "    min_count=5, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "\n",
    "    workers=10,  # Training thread count\n",
    "\n",
    "    sg=1,        # 0: CBOW, 1: Skip-gram.\n",
    "\n",
    "    hs=0,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "    negative=5   # Nmber of negative samples\n",
    "                 #   Default is 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(\n",
    "    corpus_bigrams,\n",
    "    progress_per=20000  # Tweaks how often progress is reported\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "  Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "\n",
    "model.train(\n",
    "    processed_sents,\n",
    "    total_examples=len(processed_sents),\n",
    "    epochs=10,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    ")\n",
    "\n",
    "print('  Done.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showcase sample word vector and results layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for Uncertain:\n",
      "Length of vector: 100\n",
      "[-0.3484722   0.10163841 -0.01252631  0.01786912  0.17679088 -0.30190015\n",
      " -0.26260594  0.10047907 -0.07748776  0.09296066 -0.18984024 -0.12112519\n",
      " -0.19701016 -0.22183388  0.2633721  -0.20558923  0.28330415 -0.16902506\n",
      "  0.04455652 -0.38614827 -0.02205837  0.12179832  0.18581161 -0.08096561\n",
      "  0.12242373  0.04912557 -0.11092206  0.22599871 -0.17253287  0.29855505\n",
      "  0.3332483   0.0661625  -0.0473337   0.00911532  0.06316879  0.06293564\n",
      "  0.02696742 -0.0372304  -0.06809297 -0.19113077 -0.05350975  0.00749517\n",
      " -0.03151321 -0.09120497  0.21621387 -0.13368987 -0.04868797  0.03340903\n",
      " -0.00315683  0.11653571  0.07077207 -0.05241055 -0.21221593  0.09143794\n",
      " -0.28332743  0.22272316  0.22338995  0.03178673 -0.30422604  0.28374264\n",
      " -0.00108746  0.07090506  0.11222957 -0.04180789 -0.2734059   0.31775865\n",
      "  0.15461881 -0.08890928 -0.04745176  0.23896833  0.05201704 -0.00560736\n",
      "  0.24608867 -0.13530016  0.19973059  0.2777233   0.09203767 -0.03666746\n",
      " -0.2879699  -0.02727102 -0.48390394  0.1249141   0.1051375   0.26319677\n",
      "  0.03179618 -0.21270823 -0.18668647  0.35604048  0.37810835  0.03003606\n",
      "  0.01858783  0.0976871  -0.18324868  0.0751633   0.2597924  -0.04570511\n",
      "  0.1606021   0.06243643 -0.04441595 -0.00790171]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "vector = word_vectors['uncertain']\n",
    "\n",
    "print('Vector for Uncertain:')\n",
    "print(f'Length of vector: {len(vector)}')\n",
    "print(f'{vector}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocab List: 14,046\n",
      "['much', 'way', 'people', 'mr', 'us', 'little', 'state', 'good', 'make', 'world', 'still', 'see', 'men', 'work', 'long', 'get', 'life', 'never', 'day', 'another']\n"
     ]
    }
   ],
   "source": [
    "vocab = model.wv.key_to_index.keys()\n",
    "vocab_list = []\n",
    "for i in vocab:\n",
    "    vocab_list.append(i)\n",
    "\n",
    "print(f'Length of Vocab List: {len(vocab_list):,}')\n",
    "print(vocab_list[20:40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>much</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>world</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>still</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>see</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>men</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>work</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>get</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>life</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>never</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>another</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "0      much    937\n",
       "1       way    909\n",
       "2    people    847\n",
       "3        mr    844\n",
       "4        us    838\n",
       "5    little    831\n",
       "6     state    807\n",
       "7      good    806\n",
       "8      make    794\n",
       "9     world    787\n",
       "10    still    782\n",
       "11      see    772\n",
       "12      men    763\n",
       "13     work    762\n",
       "14     long    753\n",
       "15      get    749\n",
       "16     life    715\n",
       "17    never    697\n",
       "18      day    687\n",
       "19  another    684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = []\n",
    "\n",
    "for i in range(20,40):\n",
    "    # Pick a random word.\n",
    "    word = vocab_list[i]\n",
    "    count = model.wv.get_vecattr(word, 'count')\n",
    "    word_counts.append((word, count))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(word_counts, columns=['Word', 'Count'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivist: Similarity = 0.8871\n",
      "authenticity: Similarity = 0.8681\n",
      "incorrect: Similarity = 0.8680\n",
      "urges: Similarity = 0.8644\n",
      "experimenter: Similarity = 0.8608\n",
      "catharsis: Similarity = 0.8605\n",
      "uniqueness: Similarity = 0.8587\n",
      "mediums: Similarity = 0.8556\n",
      "comprehend: Similarity = 0.8552\n",
      "gabriels: Similarity = 0.8537\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar('uncertain', topn=10)\n",
    "\n",
    "# Print the most similar words and their similarity scores\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: Similarity = {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
